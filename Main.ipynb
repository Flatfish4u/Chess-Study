{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import chess.pgn\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import chess.engine\n",
    "import sys\n",
    "import logging\n",
    "import math\n",
    "import random\n",
    "import tqdm\n",
    "from enum import Enum\n",
    "from elocator_test.complexity.model import ChessModel\n",
    "import torch\n",
    "from elocator_test.encoder import fen_encoder\n",
    "\n",
    "\n",
    "# Configure logging to print to stdout\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(levelname)s: %(message)s\", stream=sys.stdout\n",
    ")\n",
    "\n",
    "# Configure plotting style\n",
    "sns.set(style=\"whitegrid\")\n",
    "# Replace with the actual path to your general population PGN file\n",
    "GENERAL_PGN_FILE_PATH = '/Users/benjaminrosales/Desktop/Chess Data/Materials & Data/Lichess Published Datasets/lichess_db_standard_rated_2017-05.pgn'\n",
    "\n",
    "# Path to your Stockfish executable\n",
    "STOCKFISH_PATH = \"/opt/homebrew/bin/stockfish\"\n",
    "\n",
    "# List of ADHD players' usernames (Lichess)\n",
    "ADHD_USERNAMES = [\n",
    "    \"teoeo\",\n",
    "    \"Tobermorey\", \n",
    "    \"apostatlet\",\n",
    "    \"LovePump1000\",\n",
    "    \"StuntmanAndy\",\n",
    "    \"ChessyChesterton12\",\n",
    "    \"yastoon\",\n",
    "    \"SonnyDayz11\",\n",
    "    \"Xiroir\",\n",
    "    \"StellaAthena\",\n",
    "    \"MagikPigeon\",\n",
    "    \"pawnsgoback\",\n",
    "    \"Dru403\",\n",
    "    \"ellehooq\", \n",
    "    \"Euph4life\",\n",
    "    \"Matthew-Marchand\",\n",
    "    \"Rosey12\",\n",
    "    \"s0mething213\",\n",
    "    \"B1SH0P_B1SH0P\",\n",
    "    \"Wildwood\",\n",
    "    \"Kanaan92\",\n",
    "    \"jonesmh\"\n",
    "]\n",
    "\n",
    "#WrapperClass\n",
    "class ElocatorModel:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = ChessModel()\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "        self.model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElocatorAnalyzer:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = ChessModel()\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Correct percentile ranges from the repo\n",
    "        self.percentile_ranges = {\n",
    "            1: (0, 0.006848618667572737),\n",
    "            2: (0.006848618667572737, 0.007860606908798218),\n",
    "            3: (0.007860606908798218, 0.0093873867765069),\n",
    "            4: (0.0093873867765069, 0.010885232314467431),\n",
    "            5: (0.010885232314467431, 0.01191701553761959),\n",
    "            6: (0.01191701553761959, 0.012793240323662757),\n",
    "            7: (0.012793240323662757, 0.013946877606213093),\n",
    "            8: (0.013946877606213093, 0.015834777429699905),\n",
    "            9: (0.015834777429699905, 0.02067287489771843),\n",
    "            10: (0.02067287489771843, 1)\n",
    "        }\n",
    "    \n",
    "    def map_prediction_to_complexity(self, prediction):\n",
    "        \"\"\"Maps raw model output to complexity score (1-10)\"\"\"\n",
    "        for level, (low, high) in self.percentile_ranges.items():\n",
    "            if low <= prediction <= high:\n",
    "                return level\n",
    "        return None  # Handle predictions outside expected range\n",
    "    \n",
    "    def get_position_complexity(self, fen):\n",
    "        \"\"\"Get complexity score for a single position\"\"\"\n",
    "        try:\n",
    "            # Sanitize the FEN string before processing\n",
    "            clean_fen = sanitize_fen(fen)\n",
    "            if clean_fen is None:\n",
    "                return None\n",
    "                \n",
    "            encoded_position = fen_encoder(clean_fen)\n",
    "            position_tensor = torch.FloatTensor(encoded_position).unsqueeze(0)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                raw_prediction = self.model(position_tensor).item()\n",
    "                complexity_score = self.map_prediction_to_complexity(raw_prediction)\n",
    "                return complexity_score\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing FEN {fen}: {str(e)}\")\n",
    "            return None\n",
    "            \n",
    "    def analyze_game(self, pgn_game):\n",
    "        board = pgn_game.board()\n",
    "        node = pgn_game\n",
    "        positions = []\n",
    "        \n",
    "        # Get initial position\n",
    "        try:\n",
    "            complexity = self.get_position_complexity(board.fen())\n",
    "            positions.append({\n",
    "                'fen': board.fen(),\n",
    "                'complexity': complexity,\n",
    "                'move_number': 0\n",
    "            })\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error analyzing initial position: {str(e)}\")\n",
    "        \n",
    "        # Process each move\n",
    "        while node.variations:\n",
    "            try:\n",
    "                next_node = node.variations[0]\n",
    "                move = next_node.move\n",
    "                board.push(move)\n",
    "                \n",
    "                complexity = self.get_position_complexity(board.fen())\n",
    "                if complexity is not None:  # Only append positions we can analyze\n",
    "                    positions.append({\n",
    "                        'fen': board.fen(),\n",
    "                        'complexity': complexity,\n",
    "                        'move_number': len(board.move_stack)\n",
    "                    })\n",
    "                \n",
    "                node = next_node\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error analyzing position at move {len(board.move_stack)}: {str(e)}\")\n",
    "                break\n",
    "                \n",
    "        return positions\n",
    "\n",
    "# Create global instance\n",
    "elocator = ElocatorAnalyzer('elocator_test/complexity/models/model.pth')\n",
    "\n",
    "# Create global instance\n",
    "elocator = ElocatorAnalyzer('elocator_test/complexity/models/model.pth')\n",
    "# Create global instance\n",
    "elocator = ElocatorAnalyzer('elocator_test/complexity/models/model.pth')\n",
    "    \n",
    "def get_position_complexity(self, fen):\n",
    "        \"\"\"Get complexity score for a single position\"\"\"\n",
    "        encoded_position = fen_encoder(fen)\n",
    "        position_tensor = torch.FloatTensor(encoded_position).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            complexity = self.model(position_tensor)\n",
    "        return complexity.item()\n",
    "    \n",
    "def sanitize_fen(fen):\n",
    "    \"\"\"\n",
    "    Sanitize and validate a FEN string for standard chess.\n",
    "    Returns None if the FEN is invalid or from a variant game.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # If we see brackets or special characters, it's likely a variant game\n",
    "        if '[' in fen or ']' in fen or '~' in fen:\n",
    "            return None\n",
    "            \n",
    "        # Remove any non-standard characters\n",
    "        valid_chars = 'rnbqkpRNBQKP12345678/- '\n",
    "        cleaned_fen = ''.join(c for c in fen if c in valid_chars)\n",
    "        \n",
    "        # Get position part (everything before first space)\n",
    "        position_part = cleaned_fen.split()[0] if ' ' in cleaned_fen else cleaned_fen\n",
    "        \n",
    "        # Validate basic FEN structure\n",
    "        ranks = position_part.split('/')\n",
    "        if len(ranks) != 8:\n",
    "            return None\n",
    "            \n",
    "        # Validate each rank\n",
    "        for rank in ranks:\n",
    "            spaces = 0\n",
    "            for char in rank:\n",
    "                if char.isdigit():\n",
    "                    spaces += int(char)\n",
    "                else:\n",
    "                    spaces += 1\n",
    "            if spaces != 8:\n",
    "                return None\n",
    "                \n",
    "        # Return standardized FEN string\n",
    "        return f\"{position_part} w - - 0 1\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"FEN sanitization failed: {fen}\")\n",
    "        logging.error(f\"Error: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_int(value, default=None):\n",
    "    try:\n",
    "        return int(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return default\n",
    "\"\"\"\n",
    "Setting up Time Functions\n",
    "\"\"\"\n",
    "\n",
    "def parse_clock_time(comment):\n",
    "    match = re.search(r'\\[%clk (\\d+):(\\d+):(\\d+)\\]', comment)  # Adjust regex if needed\n",
    "    if match:\n",
    "        hours = int(match.group(1))\n",
    "        minutes = int(match.group(2))\n",
    "        seconds = int(match.group(3))\n",
    "        return hours * 3600 + minutes * 60 + seconds  # Total seconds\n",
    "    return None\n",
    "\n",
    "## Determine if a player is under time pressure based on van Harreveld et al. (2007) criteria ---\n",
    "\n",
    "def is_under_time_pressure(time_remaining, initial_time, time_spent):\n",
    "    \"\"\"\n",
    "    Determine time pressure, accounting for premoves and missing data\n",
    "    - Premoves (time_spent = 0) should never count as time pressure\n",
    "    - Missing time data should be handled safely\n",
    "    \"\"\"\n",
    "    # Handle None/missing values\n",
    "    if any(x is None for x in [time_remaining, initial_time]):\n",
    "        return False\n",
    "        \n",
    "    # Handle invalid values\n",
    "    try:\n",
    "        time_remaining = float(time_remaining)\n",
    "        initial_time = float(initial_time)\n",
    "        # time_spent can be None for missing data or 0 for premoves\n",
    "        time_spent = float(time_spent) if time_spent is not None else None\n",
    "    except (TypeError, ValueError):\n",
    "        return False\n",
    "        \n",
    "    # Invalid time states\n",
    "    if initial_time <= 0 or time_remaining < 0:\n",
    "        return False\n",
    "        \n",
    "    # If it's a premove (time_spent = 0) or missing time data,\n",
    "    # only check absolute and relative time remaining\n",
    "    absolute_pressure = time_remaining < 30  # Less than 30 seconds\n",
    "    relative_pressure = time_remaining < (0.1 * initial_time)  # Less than 10% of initial time\n",
    "        \n",
    "    return absolute_pressure or relative_pressure\n",
    "\n",
    "class TimeControlType(Enum):\n",
    "    CLASSICAL = \"Classical\"\n",
    "    RAPID = \"Rapid\"\n",
    "    BLITZ = \"Blitz\"\n",
    "    BULLET = \"Bullet\"\n",
    "    UNKNOWN = \"Unknown\"\n",
    "\n",
    "#Parsing and Categorizing Time Control\n",
    "def parse_time_control(time_control):\n",
    "    \"\"\"Parse time control string from Lichess format (already in seconds)\"\"\"\n",
    "    if not time_control or time_control == \"unknown\":\n",
    "        return None, None, TimeControlType.UNKNOWN\n",
    "        \n",
    "    try:\n",
    "        if \"+\" in time_control:\n",
    "            base, increment = time_control.split(\"+\")\n",
    "            initial_seconds = int(base)  # Already in seconds, don't multiply\n",
    "            increment_seconds = int(increment)\n",
    "        else:\n",
    "            initial_seconds = int(time_control)  # Already in seconds\n",
    "            increment_seconds = 0\n",
    "            \n",
    "        # Categorize based on seconds\n",
    "        if initial_seconds >= 1800:     # 30 minutes or more\n",
    "            category = TimeControlType.CLASSICAL\n",
    "        elif initial_seconds >= 600:     # 10 minutes or more\n",
    "            category = TimeControlType.RAPID\n",
    "        elif initial_seconds >= 180:     # 3 minutes or more\n",
    "            category = TimeControlType.BLITZ\n",
    "        else:                           # Less than 3 minutes\n",
    "            category = TimeControlType.BULLET\n",
    "            \n",
    "        return initial_seconds, increment_seconds, category\n",
    "        \n",
    "    except (ValueError, TypeError):\n",
    "        return None, None, TimeControlType.UNKNOWN\n",
    "\n",
    "def calculate_material(board):\n",
    "    # Returns material balance for both sides\n",
    "    material = {\"White\": 0, \"Black\": 0}\n",
    "    piece_values = {\n",
    "        chess.PAWN: 1,\n",
    "        chess.KNIGHT: 3,\n",
    "        chess.BISHOP: 3,\n",
    "        chess.ROOK: 5,\n",
    "        chess.QUEEN: 9,\n",
    "        chess.KING: 0,  # King is invaluable, but we set to 0 for simplicity\n",
    "    }\n",
    "    for piece_type in piece_values:\n",
    "        value = piece_values[piece_type]\n",
    "        material[\"White\"] += len(board.pieces(piece_type, chess.WHITE)) * value\n",
    "        material[\"Black\"] += len(board.pieces(piece_type, chess.BLACK)) * value\n",
    "    return material\n",
    "\n",
    "def categorize_position_complexity(evaluation):\n",
    "#position needs to handle both text and numeric evaluations because of \"mate scores\" \n",
    "    if evaluation is None:\n",
    "        return 'Unknown'\n",
    "    \n",
    "    # Handle mate scores\n",
    "    if isinstance(evaluation, str) and '#' in evaluation:\n",
    "        return 'Decisive Advantage'\n",
    "        \n",
    "    try:\n",
    "        eval_float = float(evaluation)\n",
    "        if abs(eval_float) < 1:\n",
    "            return 'Balanced'\n",
    "        elif abs(eval_float) < 3:\n",
    "            return 'Slight Advantage'\n",
    "        else:\n",
    "            return 'Decisive Advantage'\n",
    "    except (ValueError, TypeError):\n",
    "        return 'Unknown'\n",
    "\n",
    "def categorize_move(eval_before, eval_after):\n",
    "    if eval_before is None or eval_after is None:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    # Handle mate scores\n",
    "    if isinstance(eval_after, str) and '#' in eval_after:\n",
    "        if '-' in eval_after:\n",
    "            return \"Forced Checkmate (Losing)\"\n",
    "        return \"Forced Checkmate (Winning)\"\n",
    "    \n",
    "    try:\n",
    "        eval_before = float(eval_before)\n",
    "        eval_after = float(eval_after)\n",
    "    except (ValueError, TypeError):\n",
    "        return \"Unknown\"\n",
    "\n",
    "    ##numeric evaluation\n",
    "    SATURATION_LIMIT = 1000  # Equivalent to a 10-pawn advantage\n",
    "    \n",
    "    ##eval change\n",
    "    eval_change = eval_after - eval_before\n",
    "\n",
    "    if abs(eval_after) >= SATURATION_LIMIT:\n",
    "        return \"Winning Position\" if eval_after > 0 else \"Losing Position\"\n",
    "\n",
    "    ##mistake calculator\n",
    "    if eval_change <= -300:\n",
    "        return \"Blunder\"\n",
    "    elif eval_change <= -150:\n",
    "        return \"Mistake\"\n",
    "    elif eval_change <= -50:\n",
    "        return \"Inaccuracy\"\n",
    "    elif eval_change >= 300:\n",
    "        return \"Brilliant Move\"\n",
    "    elif eval_change >= 150:\n",
    "        return \"Great Move\"\n",
    "    elif eval_change >= 50:\n",
    "        return \"Good Move\"\n",
    "    else:\n",
    "        return \"Normal\"\n",
    "\n",
    "\n",
    "def raw_winning_chances(cp):\n",
    "    MULTIPLIER = -0.00368208\n",
    "    return 2 / (1 + math.exp(MULTIPLIER * cp)) - 1\n",
    "\n",
    "def cp_winning_chances(cp):\n",
    "    cp = max(-1000, min(cp, 1000))\n",
    "    return raw_winning_chances(cp)\n",
    "\n",
    "def mate_winning_chances(mate):\n",
    "    cp = (21 - min(10, abs(mate))) * 100\n",
    "    signed_cp = cp * (1 if mate > 0 else -1)\n",
    "    return raw_winning_chances(signed_cp)\n",
    "\n",
    "def eval_winning_chances(eval_str):\n",
    "    if eval_str is None:\n",
    "        return None\n",
    "    if '#' in str(eval_str):\n",
    "        # Mate in N moves\n",
    "        mate_str = str(eval_str).replace('#', '')\n",
    "        try:\n",
    "            mate = int(mate_str)\n",
    "            return mate_winning_chances(mate)\n",
    "        except ValueError:\n",
    "            return None\n",
    "    else:\n",
    "        try:\n",
    "            cp = float(eval_str) * 100  # Convert from pawns to centipawns\n",
    "            return cp_winning_chances(cp)\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "\n",
    "def safe_int(value, default=None):\n",
    "    try:\n",
    "        return int(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return default\n",
    "\n",
    "\n",
    "def parse_clock_time(comment):\n",
    "    match = re.search(r'\\[%clk (\\d+):(\\d+):(\\d+)\\]', comment)  # Adjust regex if needed\n",
    "    if match:\n",
    "        hours = int(match.group(1))\n",
    "        minutes = int(match.group(2))\n",
    "        seconds = int(match.group(3))\n",
    "        return hours * 3600 + minutes * 60 + seconds  # Total seconds\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_evaluation(comment):\n",
    "    match = re.search(r'%eval\\s([+-]?[\\d.]+|#-?\\d+)', comment)\n",
    "    if match:\n",
    "        eval_str = match.group(1)\n",
    "        if '#' in eval_str:\n",
    "            # Mate in N moves\n",
    "            return eval_str\n",
    "        else:\n",
    "            return float(eval_str)  # Convert to float\n",
    "    return None\n",
    "\n",
    "\n",
    "def categorize_error(eval_change, player_color=\"white\"):\n",
    "    if eval_change is None:\n",
    "        return \"Unknown\"\n",
    "        \n",
    "    # Normalize eval_change to player's perspective\n",
    "    if player_color.lower() == \"black\":\n",
    "        eval_change = -eval_change\n",
    "        \n",
    "    # Now we're already in centipawns, no need to divide by 100\n",
    "    if eval_change <= -300:  \n",
    "        return \"Blunder\"\n",
    "    elif eval_change <= -150:\n",
    "        return \"Mistake\"\n",
    "    elif eval_change <= -50:\n",
    "        return \"Inaccuracy\"\n",
    "    else:\n",
    "        return \"Normal\"\n",
    "\n",
    "def calculate_material(board):\n",
    "    # Returns material balance for both sides\n",
    "    material = {\"White\": 0, \"Black\": 0}\n",
    "    piece_values = {\n",
    "        chess.PAWN: 1,\n",
    "        chess.KNIGHT: 3,\n",
    "        chess.BISHOP: 3,\n",
    "        chess.ROOK: 5,\n",
    "        chess.QUEEN: 9,\n",
    "        chess.KING: 0,  # King is invaluable, but we set to 0 for simplicity\n",
    "    }\n",
    "    for piece_type in piece_values:\n",
    "        value = piece_values[piece_type]\n",
    "        material[\"White\"] += len(board.pieces(piece_type, chess.WHITE)) * value\n",
    "        material[\"Black\"] += len(board.pieces(piece_type, chess.BLACK)) * value\n",
    "    return material\n",
    "\n",
    "def categorize_game_phase(board):\n",
    "    \"\"\"\n",
    "    Enhanced game phase calculation incorporating:\n",
    "    material balance \n",
    "    Piecemobility\n",
    "    pawn structure\n",
    "    position\n",
    "    \"\"\"\n",
    "    # Material values calibrated from empirical analysis\n",
    "    PIECE_VALUES = {\n",
    "        chess.KNIGHT: 782,\n",
    "        chess.BISHOP: 830,\n",
    "        chess.ROOK: 1289,\n",
    "        chess.QUEEN: 2529\n",
    "    }\n",
    "    \n",
    "    # Phase boundaries from statistical analysis\n",
    "    ENDGAME_LIMIT = 3915   # ~Queen + Rook\n",
    "    MIDGAME_LIMIT = 15258  # Total non-pawn material at start\n",
    "    PHASE_MIDGAME = 128    # Full phase scale\n",
    "    \n",
    "    def calculate_piece_mobility(board, piece_type, square):\n",
    "        \"\"\"Calculate approximate mobility for a piece\"\"\"\n",
    "        mobility = 0\n",
    "        attacks = board.attacks(square)\n",
    "        mobility = len([sq for sq in attacks if not board.is_attacked_by(not board.turn, sq)])\n",
    "        return mobility\n",
    "    \n",
    "    def evaluate_pawn_structure(board):\n",
    "        \"\"\"Evaluate pawn structure impact on phase\"\"\"\n",
    "        white_pawns = board.pieces(chess.PAWN, chess.WHITE)\n",
    "        black_pawns = board.pieces(chess.PAWN, chess.BLACK)\n",
    "        \n",
    "        # Calculate pawn structure characteristics\n",
    "        center_pawns = len([p for p in white_pawns | black_pawns \n",
    "                          if chess.square_file(p) in [3,4]])\n",
    "        passed_pawns = 0\n",
    "        for p in white_pawns:\n",
    "            if not any(black_pawns & chess.BB_FILES[chess.square_file(p)]):\n",
    "                passed_pawns += 1\n",
    "        for p in black_pawns:\n",
    "            if not any(white_pawns & chess.BB_FILES[chess.square_file(p)]):\n",
    "                passed_pawns += 1\n",
    "                \n",
    "        return center_pawns * 0.1 + passed_pawns * 0.15\n",
    "    \n",
    "    # non-pawn material\n",
    "    def evaluate_position(color):\n",
    "        material = 0\n",
    "        mobility_factor = 0\n",
    "        \n",
    "        for piece_type, value in PIECE_VALUES.items():\n",
    "            pieces = board.pieces(piece_type, color)\n",
    "            count = len(pieces)\n",
    "            material += count * value\n",
    "            \n",
    "            #mobility consideration\n",
    "            for square in pieces:\n",
    "                mobility_factor += calculate_piece_mobility(board, piece_type, square) * 0.01\n",
    "                \n",
    "        return material, mobility_factor\n",
    "    \n",
    "    # Calculate both sides\n",
    "    w_material, w_mobility = evaluate_position(chess.WHITE)\n",
    "    b_material, b_mobility = evaluate_position(chess.BLACK)\n",
    "    \n",
    "    # Total non-pawn material with mobility adjustment\n",
    "    total_material = w_material + b_material\n",
    "    mobility_adjustment = (w_mobility + b_mobility) * 100\n",
    "    \n",
    "    # Pawn structure impact\n",
    "    pawn_factor = evaluate_pawn_structure(board)\n",
    "    \n",
    "    # Adjust material based on mobility and pawn structure\n",
    "    adjusted_material = total_material * (1 + pawn_factor) + mobility_adjustment\n",
    "    \n",
    "    # Clamp between endgame and midgame limits\n",
    "    npm = max(ENDGAME_LIMIT, min(adjusted_material, MIDGAME_LIMIT))\n",
    "    \n",
    "    # Calculate phase score (0 = endgame, 128 = midgame)\n",
    "    phase = ((npm - ENDGAME_LIMIT) * PHASE_MIDGAME) // (MIDGAME_LIMIT - ENDGAME_LIMIT)\n",
    "    phase = max(0, min(phase, PHASE_MIDGAME))\n",
    "    \n",
    "    # Position-specific adjustments\n",
    "    if len(board.move_stack) <= 20:  # First 10 moves\n",
    "        phase = max(phase, 96)  # Ensure early moves are recognized as opening\n",
    "    \n",
    "    # Convert to categorical with clear documentation of thresholds\n",
    "    if phase >= 96:      # 75% of PHASE_MIDGAME - Clear opening characteristics\n",
    "        return \"Opening\"\n",
    "    elif phase >= 32:    # 25% of PHASE_MIDGAME - Significant material remains\n",
    "        return \"Middlegame\"\n",
    "    else:                # Limited material or simplified position\n",
    "        return \"Endgame\"\n",
    "\n",
    "def categorize_move(eval_before, eval_after):\n",
    "    if eval_before is None or eval_after is None:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    #saturation limits in centipawns to a 10pawn advantage\n",
    "    SATURATION_LIMIT = 1000  \n",
    "    MATE_SCORE = 10000 \n",
    "\n",
    "    # Calculate evaluation change\n",
    "    eval_change = eval_after - eval_before\n",
    "\n",
    "    # Handle mate scores (assuming the engine uses large numbers to indicate mate)\n",
    "    if abs(eval_after) >= MATE_SCORE:\n",
    "        if eval_after > 0:\n",
    "            return \"Forced Checkmate (Winning)\"\n",
    "        else:\n",
    "            return \"Forced Checkmate (Losing)\"\n",
    "\n",
    "    # Handle evaluation saturation\n",
    "    if abs(eval_after) >= SATURATION_LIMIT:\n",
    "        if eval_after > 0:\n",
    "            return \"Winning Position\"\n",
    "        else:\n",
    "            return \"Losing Position\"\n",
    "\n",
    "    # Categorize the move based on evaluation change\n",
    "    if eval_change <= -300:\n",
    "        return \"Blunder\"\n",
    "    elif eval_change <= -150:\n",
    "        return \"Mistake\"\n",
    "    elif eval_change <= -50:\n",
    "        return \"Inaccuracy\"\n",
    "    elif eval_change >= 300:\n",
    "        return \"Brilliant Move\"\n",
    "    elif eval_change >= 150:\n",
    "        return \"Great Move\"\n",
    "    elif eval_change >= 50:\n",
    "        return \"Good Move\"\n",
    "    else:\n",
    "        return \"Normal\"\n",
    "\n",
    "\n",
    "def raw_winning_chances(cp):\n",
    "    MULTIPLIER = -0.00368208\n",
    "    return 2 / (1 + math.exp(MULTIPLIER * cp)) - 1\n",
    "\n",
    "\n",
    "def cp_winning_chances(cp):\n",
    "    cp = max(-1000, min(cp, 1000))\n",
    "    return raw_winning_chances(cp)\n",
    "\n",
    "\n",
    "def mate_winning_chances(mate):\n",
    "    cp = (21 - min(10, abs(mate))) * 100\n",
    "    signed_cp = cp * (1 if mate > 0 else -1)\n",
    "    return raw_winning_chances(signed_cp)\n",
    "\n",
    "\n",
    "def eval_winning_chances(evaluation):\n",
    "    if evaluation is None:\n",
    "        return None\n",
    "    if isinstance(evaluation, str) and '#' in evaluation:\n",
    "        # Mate in N moves\n",
    "        mate_str = evaluation.replace('#', '')\n",
    "        try:\n",
    "            mate = int(mate_str)\n",
    "            return mate_winning_chances(mate)\n",
    "        except ValueError:\n",
    "            return None\n",
    "    else:\n",
    "        try:\n",
    "            cp = float(evaluation) * 100  # Convert from pawns to centipawns\n",
    "            return cp_winning_chances(cp)\n",
    "        except ValueError:\n",
    "            return None\n",
    "        \n",
    "\n",
    "def calculate_eval_change(prev_evaluation, evaluation, player):\n",
    "    if prev_evaluation is None or evaluation is None:\n",
    "        return None\n",
    "        \n",
    "    def process_eval(eval_str):\n",
    "        MAX_PAWNS = 15  # Cap at ±15 pawns\n",
    "        \n",
    "        if isinstance(eval_str, str) and '#' in eval_str:\n",
    "            mate_num = int(eval_str.replace('#', ''))\n",
    "            # Convert mate scores to pawns (not centipawns)\n",
    "            return MAX_PAWNS if mate_num > 0 else -MAX_PAWNS\n",
    "            \n",
    "        try:\n",
    "            # Keep everything in pawns and cap\n",
    "            val = float(eval_str)\n",
    "            return max(min(val, MAX_PAWNS), -MAX_PAWNS)\n",
    "        except ValueError:\n",
    "            return None\n",
    "    \n",
    "    try:\n",
    "        prev_val = process_eval(prev_evaluation)\n",
    "        curr_val = process_eval(evaluation)\n",
    "        \n",
    "        if prev_val is None or curr_val is None:\n",
    "            return None\n",
    "            \n",
    "        # Calculate change (still in pawns)\n",
    "        change = curr_val - prev_val\n",
    "        if player.lower() == \"black\":\n",
    "            change = -change\n",
    "            \n",
    "        return change\n",
    "        \n",
    "    except (ValueError, TypeError) as e:\n",
    "        logging.error(f\"Error calculating eval change: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_statistical_test(var, data, test_results, test_type=\"independent_t\"):\n",
    "    # Prepare data\n",
    "    group1 = data[data[\"Group\"] == \"ADHD\"][var].dropna()\n",
    "    group2 = data[data[\"Group\"] == \"General\"][var].dropna()\n",
    "\n",
    "    # Check if data is sufficient\n",
    "    if len(group1) < 10 or len(group2) < 10:\n",
    "        logging.warning(f\"Not enough data to perform statistical test on '{var}'.\")\n",
    "        return\n",
    "\n",
    "    # Test for normality\n",
    "    stat1, p1 = stats.shapiro(group1)\n",
    "    stat2, p2 = stats.shapiro(group2)\n",
    "    normal = p1 > 0.05 and p2 > 0.05\n",
    "\n",
    "    # Test for equal variances\n",
    "    stat_levene, p_levene = stats.levene(group1, group2)\n",
    "    equal_var = p_levene > 0.05\n",
    "\n",
    "    # Choose appropriate test\n",
    "    if normal and equal_var and test_type == \"independent_t\":\n",
    "        # Independent T-test\n",
    "        stat, p = stats.ttest_ind(group1, group2, equal_var=True)\n",
    "        test_name = \"Independent t-test\"\n",
    "    elif normal and not equal_var and test_type == \"independent_t\":\n",
    "        # Welch's T-test\n",
    "        stat, p = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "        test_name = \"Welch's t-test\"\n",
    "    else:\n",
    "        # Mann-Whitney U Test\n",
    "        stat, p = stats.mannwhitneyu(group1, group2, alternative=\"two-sided\")\n",
    "        test_name = \"Mann-Whitney U test\"\n",
    "\n",
    "    test_results.append(\n",
    "        {\"Variable\": var, \"Test\": test_name, \"Statistic\": stat, \"p-value\": p}\n",
    "    )\n",
    "\n",
    "\n",
    "def perform_chi_squared_test(category_var, data, test_results):\n",
    "    contingency_table = pd.crosstab(data[\"Group\"], data[category_var])\n",
    "    if contingency_table.empty or contingency_table.shape[1] == 0:\n",
    "        logging.warning(f\"Contingency table is empty for variable '{category_var}'.\")\n",
    "        return\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "    test_results.append(\n",
    "        {\n",
    "            \"Variable\": category_var,\n",
    "            \"Test\": \"Chi-Squared test\",\n",
    "            \"Statistic\": chi2,\n",
    "            \"p-value\": p,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "Game Processing Functions"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Fetching general population games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting games: 100%|██████████| 10000/10000 [03:59<00:00, 41.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "ELO Distribution:\n",
      "INFO: ELO 800-850: 3 games\n",
      "INFO: ELO 850-900: 6 games\n",
      "INFO: ELO 900-950: 21 games\n",
      "INFO: ELO 950-1000: 33 games\n",
      "INFO: ELO 1000-1050: 76 games\n",
      "INFO: ELO 1050-1100: 97 games\n",
      "INFO: ELO 1100-1150: 131 games\n",
      "INFO: ELO 1150-1200: 194 games\n",
      "INFO: ELO 1200-1250: 266 games\n",
      "INFO: ELO 1250-1300: 302 games\n",
      "INFO: ELO 1300-1350: 370 games\n",
      "INFO: ELO 1350-1400: 468 games\n",
      "INFO: ELO 1400-1450: 553 games\n",
      "INFO: ELO 1450-1500: 682 games\n",
      "INFO: ELO 1500-1550: 671 games\n",
      "INFO: ELO 1550-1600: 665 games\n",
      "INFO: ELO 1600-1650: 663 games\n",
      "INFO: ELO 1650-1700: 755 games\n",
      "INFO: ELO 1700-1750: 685 games\n",
      "INFO: ELO 1750-1800: 616 games\n",
      "INFO: ELO 1800-1850: 586 games\n",
      "INFO: ELO 1850-1900: 497 games\n",
      "INFO: ELO 1900-1950: 441 games\n",
      "INFO: ELO 1950-2000: 335 games\n",
      "INFO: ELO 2000-2050: 255 games\n",
      "INFO: ELO 2050-2100: 209 games\n",
      "INFO: ELO 2100-2150: 145 games\n",
      "INFO: ELO 2150-2200: 99 games\n",
      "INFO: ELO 2200-2250: 67 games\n",
      "INFO: ELO 2250-2300: 42 games\n",
      "INFO: ELO 2300-2350: 22 games\n",
      "INFO: ELO 2350-2400: 12 games\n",
      "INFO: ELO 2400-2450: 11 games\n",
      "INFO: ELO 2450-2500: 8 games\n",
      "INFO: ELO 2500-2550: 8 games\n",
      "INFO: ELO 2550-2600: 4 games\n",
      "INFO: ELO 2600-2650: 1 games\n",
      "INFO: ELO 2650-2700: 1 games\n",
      "INFO: Successfully collected 10000 games\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def fetch_lichess_games(username, max_games=4000):  # Increase max_games\n",
    "    url = f\"https://lichess.org/api/games/user/{username}\"\n",
    "    params = {\n",
    "        \"max\": max_games,\n",
    "        \"moves\": True,\n",
    "        \"evals\": True,  # Include evaluations in the PGN comments\n",
    "        \"clocks\": True,  # Include clock times in the PGN comments\n",
    "    }\n",
    "    headers = {\"Accept\": \"application/x-chess-pgn\"}\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        logging.warning(\n",
    "            f\"Failed to fetch games for user '{username}'. Status code: {response.status_code}\"\n",
    "        )\n",
    "        return []\n",
    "    pgn_text = response.text\n",
    "    games = []\n",
    "    pgn_io = io.StringIO(pgn_text)\n",
    "    while True:\n",
    "        game = chess.pgn.read_game(pgn_io)\n",
    "        if game is None:\n",
    "            break\n",
    "\n",
    "        # Check if the game contains evaluations\n",
    "        has_evaluation = False\n",
    "        node = game\n",
    "        while node.variations:\n",
    "            next_node = node.variations[0]\n",
    "            comment = next_node.comment\n",
    "            if \"%eval\" in comment:\n",
    "                has_evaluation = True\n",
    "                break\n",
    "            node = next_node\n",
    "\n",
    "        if has_evaluation:\n",
    "            games.append(game)\n",
    "\n",
    "    logging.info(f\"Fetched {len(games)} games with evaluations for user '{username}'.\")\n",
    "    return games\n",
    "\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def count_games_in_pgn(pgn_file_path):\n",
    "    \"\"\"Count total games in PGN file with progress bar\"\"\"\n",
    "    count = 0\n",
    "    file_size = os.path.getsize(pgn_file_path)\n",
    "    \n",
    "    with open(pgn_file_path, \"r\", encoding=\"utf-8\") as pgn_file:\n",
    "        pbar = tqdm(total=file_size, desc=\"Counting games\", unit='B', unit_scale=True)\n",
    "        for line in pgn_file:\n",
    "            if line.startswith('[Event \"'):\n",
    "                count += 1\n",
    "            pbar.update(len(line.encode('utf-8')))\n",
    "        pbar.close()\n",
    "    return count\n",
    "\n",
    "def validate_game_evaluations(game):\n",
    "    \"\"\"Validate game has proper evaluation structure\"\"\"\n",
    "    try:\n",
    "        node = game\n",
    "        while node.variations:\n",
    "            next_node = node.variations[0]\n",
    "            if \"%eval\" in next_node.comment:\n",
    "                return True\n",
    "            node = next_node\n",
    "        return False\n",
    "    except (IndexError, AttributeError):\n",
    "        return False\n",
    "\n",
    "def process_pgn_file(pgn_file_path, max_games=10000, chunk_size=1000):\n",
    "    games = []\n",
    "    elo_distribution = {}\n",
    "    \n",
    "    try:\n",
    "        with open(pgn_file_path, \"r\", encoding=\"utf-8\") as pgn_file:\n",
    "            pbar = tqdm(total=max_games, desc=\"Collecting games\")\n",
    "            \n",
    "            while len(games) < max_games:\n",
    "                chunk_count = 0\n",
    "                current_chunk = []\n",
    "                \n",
    "                while chunk_count < chunk_size:\n",
    "                    game = chess.pgn.read_game(pgn_file)\n",
    "                    if game is None:\n",
    "                        break\n",
    "                        \n",
    "                    # Quick validation before adding to chunk\n",
    "                    if (game.headers and \n",
    "                        game.headers.get(\"Variant\", \"Standard\").lower() == \"standard\" and\n",
    "                        all(game.headers.get(key, \"\") != \"\" for key in [\"WhiteElo\", \"BlackElo\", \"TimeControl\"]) and\n",
    "                        validate_game_evaluations(game)):  # Added evaluation validation\n",
    "                        current_chunk.append(game)\n",
    "                        chunk_count += 1\n",
    "                \n",
    "                if not current_chunk:\n",
    "                    break\n",
    "                \n",
    "                sample_size = min(chunk_size // 2, max_games - len(games))\n",
    "                sampled_games = random.sample(current_chunk, min(sample_size, len(current_chunk)))\n",
    "                \n",
    "                for game in sampled_games:\n",
    "                    if len(games) >= max_games:\n",
    "                        break\n",
    "                    \n",
    "                    white_elo = safe_int(game.headers.get(\"WhiteElo\", 0))\n",
    "                    black_elo = safe_int(game.headers.get(\"BlackElo\", 0))\n",
    "                    time_control = game.headers.get(\"TimeControl\", \"unknown\")\n",
    "                    \n",
    "                    if all([white_elo, black_elo, time_control != \"unknown\"]):\n",
    "                        avg_elo = (white_elo + black_elo) // 2\n",
    "                        elo_bin = (avg_elo // 50) * 50\n",
    "                        elo_distribution[elo_bin] = elo_distribution.get(elo_bin, 0) + 1\n",
    "                        games.append(game)\n",
    "                        pbar.update(1)\n",
    "            \n",
    "            pbar.close()\n",
    "            \n",
    "            logging.info(\"\\nELO Distribution:\")\n",
    "            for elo_bin in sorted(elo_distribution.keys()):\n",
    "                count = elo_distribution[elo_bin]\n",
    "                logging.info(f\"ELO {elo_bin}-{elo_bin+50}: {count} games\")\n",
    "            \n",
    "        logging.info(f\"Successfully collected {len(games)} games\")\n",
    "                           \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to read PGN file '{pgn_file_path}': {e}\")\n",
    "    \n",
    "    return games\n",
    "\n",
    "# Usage\n",
    "logging.info(\"Fetching general population games...\")\n",
    "general_games = process_pgn_file(GENERAL_PGN_FILE_PATH, max_games=10000)\n",
    "\n",
    "\n",
    "def process_games(games, group_label, engine):\n",
    "    all_moves = []\n",
    "    total_games = len(games)\n",
    "    rated_games = 0\n",
    "    standard_games = 0\n",
    "    eval_games = 0\n",
    "    \n",
    "    logging.info(f\"\\nProcessing {total_games} games for {group_label} group\")\n",
    "    \n",
    "    for game in tqdm(games, desc=f\"Processing {group_label} games\"):\n",
    "        try:\n",
    "            # 1. Filter for standard chess and rated games\n",
    "            variant = game.headers.get(\"Variant\", \"Standard\")\n",
    "            event = game.headers.get(\"Event\", \"Unknown\")\n",
    "            \n",
    "            # Skip non-standard chess games\n",
    "            if variant.lower() != \"standard\":\n",
    "                continue\n",
    "            standard_games += 1\n",
    "            \n",
    "            # Check if game is rated (checking both headers and event description)\n",
    "            rated = (\"rated\" in event.lower() or \n",
    "                    game.headers.get(\"Rated\", \"False\").lower() == \"true\")\n",
    "            if not rated:\n",
    "                continue\n",
    "            rated_games += 1\n",
    "            \n",
    "            # 2. Initialize basic game data\n",
    "            board = game.board()\n",
    "            game_id = game.headers.get(\"Site\", \"Unknown\")\n",
    "            white = game.headers.get(\"White\", \"Unknown\")\n",
    "            black = game.headers.get(\"Black\", \"Unknown\")\n",
    "            result = game.headers.get(\"Result\", \"Unknown\")\n",
    "            white_elo = safe_int(game.headers.get(\"WhiteElo\", None))\n",
    "            black_elo = safe_int(game.headers.get(\"BlackElo\", None))\n",
    "            time_control = game.headers.get(\"TimeControl\", \"Unknown\")\n",
    "            \n",
    "            # 3. ADHD player identification\n",
    "            white_has_adhd = white in ADHD_USERNAMES\n",
    "            black_has_adhd = black in ADHD_USERNAMES\n",
    "            \n",
    "            # 4. Time control parsing\n",
    "            initial_time, increment, time_category = parse_time_control(time_control)\n",
    "            \n",
    "            # 5. Game traversal initialization\n",
    "            node = game\n",
    "            move_number = 0\n",
    "            prev_evaluation = None\n",
    "            current_material = calculate_material(board)\n",
    "            prev_time_remaining = None\n",
    "            prev_winning_chances = None\n",
    "            \n",
    "            # 6. Verify game has evaluations\n",
    "            if not any(\"%eval\" in node.variations[0].comment for node in game.mainline()):\n",
    "                continue\n",
    "            eval_games += 1\n",
    "\n",
    "            # 7. Process moves\n",
    "            while node.variations:\n",
    "                next_node = node.variations[0]\n",
    "                move = next_node.move\n",
    "                san = board.san(move)\n",
    "                move_number += 1\n",
    "                player = \"White\" if board.turn else \"Black\"\n",
    "                \n",
    "                # Get position evaluation data\n",
    "                try:\n",
    "                    position_complexity = elocator.get_position_complexity(board.fen())\n",
    "                except Exception as e:\n",
    "                    position_complexity = None\n",
    "                \n",
    "                # ADHD status for current move\n",
    "                is_adhd_move = (player == \"White\" and white_has_adhd) or \\\n",
    "                              (player == \"Black\" and black_has_adhd)\n",
    "                \n",
    "                # Extract move metadata\n",
    "                comment = next_node.comment\n",
    "                time_remaining = parse_clock_time(comment)\n",
    "                evaluation = parse_evaluation(comment)\n",
    "                \n",
    "                # Time calculations\n",
    "                time_spent = (prev_time_remaining - time_remaining) if all(x is not None for x in [prev_time_remaining, time_remaining]) else None\n",
    "                time_spent = time_spent if time_spent and time_spent > 0 else None\n",
    "                \n",
    "                under_pressure = is_under_time_pressure(\n",
    "                    time_remaining=time_remaining,\n",
    "                    initial_time=initial_time,\n",
    "                    time_spent=time_spent\n",
    "                )\n",
    "                \n",
    "                # Calculate winning chances\n",
    "                winning_chances = eval_winning_chances(evaluation)\n",
    "                winning_chances_change = winning_chances - prev_winning_chances if all(x is not None for x in [prev_winning_chances, winning_chances]) else None\n",
    "                \n",
    "                # Skip positions without evaluations\n",
    "                if evaluation is None:\n",
    "                    board.push(move)\n",
    "                    node = next_node\n",
    "                    prev_time_remaining = time_remaining\n",
    "                    current_material = calculate_material(board)\n",
    "                    prev_winning_chances = winning_chances\n",
    "                    continue\n",
    "                \n",
    "                # Execute move and calculate changes\n",
    "                board.push(move)\n",
    "                \n",
    "                # Evaluation change calculation\n",
    "                eval_change = calculate_eval_change(prev_evaluation, evaluation, player)\n",
    "                if eval_change is not None:\n",
    "                    eval_change = eval_change * 100\n",
    "\n",
    "                \n",
    "                new_material = calculate_material(board)\n",
    "                material_diff = new_material[player] - current_material[player]\n",
    "                is_sacrifice = material_diff < 0\n",
    "                game_phase = categorize_game_phase(board)\n",
    "                position_complexity_category = categorize_position_complexity(prev_evaluation)\n",
    "                error_category = categorize_error(eval_change, player)  # Note: passing player here is important\n",
    "                \n",
    "                # Compile move data\n",
    "                move_data = {\n",
    "                    'game_id': game_id,\n",
    "                    'event': event,\n",
    "                    'date': game.headers.get(\"UTCDate\", \"Unknown\"),\n",
    "                    'result': result,\n",
    "                    'white': white,\n",
    "                    'black': black,\n",
    "                    'white_elo': white_elo,\n",
    "                    'black_elo': black_elo,\n",
    "                    'adhd_player': white if white_has_adhd else (black if black_has_adhd else None),\n",
    "                    'move_number': move_number,\n",
    "                    'player': player,\n",
    "                    'san': san,\n",
    "                    'fen': board.fen(),\n",
    "                    'game_phase': game_phase,\n",
    "                    'is_adhd_move': is_adhd_move,\n",
    "                    'position_complexity': position_complexity,\n",
    "                    'position_complexity_category': position_complexity_category,\n",
    "                    'evaluation': evaluation,\n",
    "                    'eval_change': eval_change,\n",
    "                    'error_category': categorize_error(eval_change, player),\n",
    "                    'winning_chances': winning_chances,\n",
    "                    'winning_chances_change': winning_chances_change,\n",
    "                    'material_diff': material_diff,\n",
    "                    'is_sacrifice': is_sacrifice,\n",
    "                    'time_control': time_control,\n",
    "                    'time_control_category': time_category.value if time_category else None,\n",
    "                    'initial_time_seconds': initial_time,\n",
    "                    'increment_seconds': increment,\n",
    "                    'time_remaining': time_remaining,\n",
    "                    'time_spent': time_spent,\n",
    "                    'under_time_pressure': under_pressure,\n",
    "                    'group': group_label\n",
    "                }\n",
    "                \n",
    "                all_moves.append(move_data)\n",
    "                \n",
    "                # Update previous values\n",
    "                prev_evaluation = evaluation\n",
    "                prev_time_remaining = time_remaining\n",
    "                current_material = new_material\n",
    "                prev_winning_chances = winning_chances\n",
    "                node = next_node\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing game {game_id}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Processing summary\n",
    "    logging.info(f\"\\nProcessing Summary for {group_label}:\")\n",
    "    logging.info(f\"Total games: {total_games}\")\n",
    "    logging.info(f\"Standard chess games: {standard_games}\")\n",
    "    logging.info(f\"Rated games: {rated_games}\")\n",
    "    logging.info(f\"Games with evaluations: {eval_games}\")\n",
    "    logging.info(f\"Total moves processed: {len(all_moves)}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    moves_df = pd.DataFrame(all_moves)\n",
    "    \n",
    "    return moves_df\n",
    "\n",
    "# If you want to specify a particular column order, you can reorder the DataFrame after creation.s\n",
    "column_order = [\n",
    "    'GameID', 'Event', 'Date', 'Result',\n",
    "    'White', 'Black', 'WhiteElo', 'BlackElo', 'ADHDPlayer',\n",
    "    'MoveNumber', 'Player', 'SAN', 'GamePhase', 'IsADHDMove',\n",
    "    'Evaluation', 'EvalChange', 'ErrorCategory', 'PositionComplexity', 'Position Complexity Category'\n",
    "    'MaterialDiff', 'IsSacrifice',\n",
    "    'TimeControl', 'TimeControlCategory', 'InitialTimeSeconds',\n",
    "    'IncrementSeconds', 'TimeRemaining', 'TimeSpent', 'UnderTimePressure',\n",
    "    'Group', 'MoveCondition'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Fetching games for user 'teoeo'...\n",
      "INFO: Fetched 1252 games with evaluations for user 'teoeo'.\n",
      "INFO: Fetching games for user 'Tobermorey'...\n",
      "INFO: Fetched 172 games with evaluations for user 'Tobermorey'.\n",
      "INFO: Fetching games for user 'apostatlet'...\n",
      "INFO: Fetched 415 games with evaluations for user 'apostatlet'.\n",
      "INFO: Fetching games for user 'LovePump1000'...\n",
      "INFO: Fetched 773 games with evaluations for user 'LovePump1000'.\n",
      "INFO: Fetching games for user 'StuntmanAndy'...\n",
      "INFO: Fetched 952 games with evaluations for user 'StuntmanAndy'.\n",
      "INFO: Fetching games for user 'ChessyChesterton12'...\n",
      "INFO: Fetched 311 games with evaluations for user 'ChessyChesterton12'.\n",
      "INFO: Fetching games for user 'yastoon'...\n",
      "INFO: Fetched 24 games with evaluations for user 'yastoon'.\n",
      "INFO: Fetching games for user 'SonnyDayz11'...\n",
      "INFO: Fetched 16 games with evaluations for user 'SonnyDayz11'.\n",
      "INFO: Fetching games for user 'Xiroir'...\n",
      "INFO: Fetched 104 games with evaluations for user 'Xiroir'.\n",
      "INFO: Fetching games for user 'StellaAthena'...\n",
      "INFO: Fetched 163 games with evaluations for user 'StellaAthena'.\n",
      "INFO: Fetching games for user 'MagikPigeon'...\n",
      "INFO: Fetched 98 games with evaluations for user 'MagikPigeon'.\n",
      "INFO: Fetching games for user 'pawnsgoback'...\n",
      "INFO: Fetched 102 games with evaluations for user 'pawnsgoback'.\n",
      "INFO: Fetching games for user 'Dru403'...\n",
      "INFO: Fetched 939 games with evaluations for user 'Dru403'.\n",
      "INFO: Fetching games for user 'ellehooq'...\n",
      "INFO: Fetched 148 games with evaluations for user 'ellehooq'.\n",
      "INFO: Fetching games for user 'Euph4life'...\n",
      "INFO: Fetched 461 games with evaluations for user 'Euph4life'.\n",
      "INFO: Fetching games for user 'Matthew-Marchand'...\n",
      "INFO: Fetched 396 games with evaluations for user 'Matthew-Marchand'.\n",
      "INFO: Fetching games for user 'Rosey12'...\n",
      "INFO: Fetched 178 games with evaluations for user 'Rosey12'.\n",
      "INFO: Fetching games for user 's0mething213'...\n",
      "INFO: Fetched 158 games with evaluations for user 's0mething213'.\n",
      "INFO: Fetching games for user 'B1SH0P_B1SH0P'...\n",
      "INFO: Fetched 148 games with evaluations for user 'B1SH0P_B1SH0P'.\n",
      "INFO: Fetching games for user 'Wildwood'...\n",
      "INFO: Fetched 599 games with evaluations for user 'Wildwood'.\n",
      "INFO: Fetching games for user 'Kanaan92'...\n",
      "INFO: Fetched 457 games with evaluations for user 'Kanaan92'.\n",
      "INFO: Fetching games for user 'jonesmh'...\n",
      "INFO: Fetched 358 games with evaluations for user 'jonesmh'.\n",
      "INFO: Initialized Stockfish engine at '/opt/homebrew/bin/stockfish'.\n",
      "INFO: Processing ADHD players' games...\n",
      "INFO: \n",
      "Processing 8224 games for ADHD group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ADHD games: 100%|██████████| 8224/8224 [14:16<00:00,  9.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "Processing Summary for ADHD:\n",
      "INFO: Total games: 8224\n",
      "INFO: Standard chess games: 7830\n",
      "INFO: Rated games: 5106\n",
      "INFO: Games with evaluations: 5106\n",
      "INFO: Total moves processed: 335386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Fetching general population games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting games: 100%|██████████| 10000/10000 [03:50<00:00, 43.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "ELO Distribution:\n",
      "INFO: ELO 800-850: 5 games\n",
      "INFO: ELO 850-900: 9 games\n",
      "INFO: ELO 900-950: 22 games\n",
      "INFO: ELO 950-1000: 30 games\n",
      "INFO: ELO 1000-1050: 79 games\n",
      "INFO: ELO 1050-1100: 86 games\n",
      "INFO: ELO 1100-1150: 145 games\n",
      "INFO: ELO 1150-1200: 203 games\n",
      "INFO: ELO 1200-1250: 259 games\n",
      "INFO: ELO 1250-1300: 274 games\n",
      "INFO: ELO 1300-1350: 403 games\n",
      "INFO: ELO 1350-1400: 476 games\n",
      "INFO: ELO 1400-1450: 534 games\n",
      "INFO: ELO 1450-1500: 670 games\n",
      "INFO: ELO 1500-1550: 688 games\n",
      "INFO: ELO 1550-1600: 628 games\n",
      "INFO: ELO 1600-1650: 659 games\n",
      "INFO: ELO 1650-1700: 727 games\n",
      "INFO: ELO 1700-1750: 701 games\n",
      "INFO: ELO 1750-1800: 641 games\n",
      "INFO: ELO 1800-1850: 598 games\n",
      "INFO: ELO 1850-1900: 527 games\n",
      "INFO: ELO 1900-1950: 448 games\n",
      "INFO: ELO 1950-2000: 330 games\n",
      "INFO: ELO 2000-2050: 252 games\n",
      "INFO: ELO 2050-2100: 225 games\n",
      "INFO: ELO 2100-2150: 130 games\n",
      "INFO: ELO 2150-2200: 86 games\n",
      "INFO: ELO 2200-2250: 68 games\n",
      "INFO: ELO 2250-2300: 35 games\n",
      "INFO: ELO 2300-2350: 21 games\n",
      "INFO: ELO 2350-2400: 8 games\n",
      "INFO: ELO 2400-2450: 12 games\n",
      "INFO: ELO 2450-2500: 8 games\n",
      "INFO: ELO 2500-2550: 8 games\n",
      "INFO: ELO 2550-2600: 2 games\n",
      "INFO: ELO 2600-2650: 2 games\n",
      "INFO: ELO 2650-2700: 1 games\n",
      "INFO: Successfully collected 10000 games\n",
      "INFO: Processing general population games...\n",
      "INFO: \n",
      "Processing 10000 games for General group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing General games: 100%|██████████| 10000/10000 [26:58<00:00,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "Processing Summary for General:\n",
      "INFO: Total games: 10000\n",
      "INFO: Standard chess games: 10000\n",
      "INFO: Rated games: 10000\n",
      "INFO: Games with evaluations: 10000\n",
      "INFO: Total moves processed: 636180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Combining datasets...\n",
      "INFO: Cleaning data...\n",
      "INFO: Total number of moves after cleaning: 447391\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- 1. Fetch and Process ADHD Players' Games -----------------------\n",
    "\n",
    "adhd_games = []\n",
    "for username in ADHD_USERNAMES:\n",
    "    logging.info(f\"Fetching games for user '{username}'...\")\n",
    "    user_games = fetch_lichess_games(username, max_games=4000)  # Adjust max_games as needed\n",
    "    adhd_games.extend(user_games)\n",
    "\n",
    "if not adhd_games:\n",
    "    logging.warning(\"No ADHD games fetched. Exiting analysis.\")\n",
    "else:\n",
    "    # Initialize the chess engine\n",
    "    try:\n",
    "        engine = chess.engine.SimpleEngine.popen_uci(STOCKFISH_PATH)\n",
    "        logging.info(f\"Initialized Stockfish engine at '{STOCKFISH_PATH}'.\")\n",
    "    except FileNotFoundError:\n",
    "        logging.critical(f\"Stockfish executable not found at '{STOCKFISH_PATH}'. Please update the path.\")\n",
    "        engine = None\n",
    "    except Exception as e:\n",
    "        logging.critical(f\"Failed to initialize Stockfish engine: {e}\")\n",
    "        engine = None\n",
    "\n",
    "    if engine is not None:\n",
    "        # ----------------------- 2. Process ADHD Players' Games -----------------------\n",
    "        \n",
    "        logging.info(\"Processing ADHD players' games...\")\n",
    "        adhd_moves_df = process_games(adhd_games, group_label='ADHD', engine=engine)\n",
    "        \n",
    "        # ----------------------- 3. Fetch and Process General Population Games -----------------------\n",
    "        \n",
    "        logging.info(\"Fetching general population games...\")\n",
    "        if not os.path.exists(GENERAL_PGN_FILE_PATH):\n",
    "            logging.error(f\"PGN file not found at path: {GENERAL_PGN_FILE_PATH}\")\n",
    "            general_games = []\n",
    "        else:\n",
    "            general_games = process_pgn_file(GENERAL_PGN_FILE_PATH, max_games = 10000)  # Adjust max_games as needed\n",
    "        \n",
    "        if not general_games:\n",
    "            logging.warning(\"No General population games to process.\")\n",
    "            general_moves_df = pd.DataFrame()\n",
    "        else:\n",
    "            logging.info(\"Processing general population games...\")\n",
    "            general_moves_df = process_games(general_games, group_label='General', engine=engine)\n",
    "        \n",
    "        # ----------------------- 4. Combine Datasets -----------------------\n",
    "\n",
    "        logging.info(\"Combining datasets...\")\n",
    "        all_moves_df = pd.concat([adhd_moves_df, general_moves_df], ignore_index=True)\n",
    "\n",
    "# ----------------------- 5. Data Cleaning -----------------------\n",
    "\n",
    "logging.info(\"Cleaning data...\")\n",
    "required_columns = ['time_spent', 'evaluation', 'eval_change', 'white_elo', 'black_elo']\n",
    "all_moves_df = all_moves_df.dropna(subset=required_columns)\n",
    "\n",
    "# Ensure 'is_sacrifice' (not 'IsSacrifice') is boolean\n",
    "all_moves_df['is_sacrifice'] = all_moves_df['is_sacrifice'].fillna(False).astype(bool)\n",
    "\n",
    "# Convert relevant columns to numeric types\n",
    "numeric_columns = ['time_spent', 'evaluation', 'eval_change', 'white_elo', 'black_elo']\n",
    "for col in numeric_columns:\n",
    "    all_moves_df[col] = pd.to_numeric(all_moves_df[col], errors='coerce')\n",
    "\n",
    "# Drop rows with NaNs resulted from non-numeric conversion\n",
    "all_moves_df = all_moves_df.dropna(subset=numeric_columns)\n",
    "\n",
    "# Create ELO brackets for analysis\n",
    "all_moves_df['elo_bracket'] = pd.cut(\n",
    "    all_moves_df.apply(lambda row: max(row['white_elo'], row['black_elo']), axis=1),\n",
    "    bins=[0, 1200, 1600, 2000, float('inf')],\n",
    "    labels=['0-1200', '1200-1600', '1600-2000', '2000+']\n",
    ")\n",
    "\n",
    "# After cleaning, output the number of moves remaining\n",
    "logging.info(f\"Total number of moves after cleaning: {len(all_moves_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Change Statistics:\n",
      "count    447391.000000\n",
      "mean        -78.137922\n",
      "std         175.756321\n",
      "min       -3000.000000\n",
      "25%         -72.000000\n",
      "50%         -19.000000\n",
      "75%          -3.000000\n",
      "max         973.000000\n",
      "Name: eval_change, dtype: float64\n",
      "\n",
      "Error Category Distribution:\n",
      "error_category\n",
      "Normal        83.6\n",
      "Inaccuracy     9.3\n",
      "Blunder        3.5\n",
      "Mistake        3.5\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Largest Evaluation Changes:\n",
      "        eval_change error_category   san\n",
      "197728        973.0        Blunder   Kd8\n",
      "230990        949.0         Normal   Kf3\n",
      "149838        910.0         Normal  Rb4+\n",
      "621993        860.0         Normal   Bf2\n",
      "123540        854.0        Blunder    c5\n",
      "\n",
      "Smallest Evaluation Changes:\n",
      "        eval_change error_category   san\n",
      "106351      -3000.0        Blunder  Qf5+\n",
      "302884      -3000.0        Blunder    h6\n",
      "312759      -3000.0        Blunder  Qf6+\n",
      "353082      -3000.0         Normal  Qxg1\n",
      "373728      -3000.0        Blunder   Qg5\n"
     ]
    }
   ],
   "source": [
    "def analyze_error_distribution(df):\n",
    "    # Print actual value ranges\n",
    "    print(\"\\nEvaluation Change Statistics:\")\n",
    "    print(df['eval_change'].describe())\n",
    "    \n",
    "    # Count error categories\n",
    "    print(\"\\nError Category Distribution:\")\n",
    "    print(df['error_category'].value_counts(normalize=True).multiply(100).round(1))\n",
    "    \n",
    "    # Look at the largest eval changes\n",
    "    print(\"\\nLargest Evaluation Changes:\")\n",
    "    print(df.nlargest(5, 'eval_change')[['eval_change', 'error_category', 'san']])\n",
    "    \n",
    "    # Look at the smallest eval changes\n",
    "    print(\"\\nSmallest Evaluation Changes:\")\n",
    "    print(df.nsmallest(5, 'eval_change')[['eval_change', 'error_category', 'san']])\n",
    "\n",
    "# Add after your data cleaning\n",
    "analyze_error_distribution(all_moves_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: === APPLYING PUBLICATION-READY DATA FIXES ===\n",
      "INFO: ✓ Fixed ELO brackets to match paper format\n",
      "INFO: ✓ Created proper player_type variables\n",
      "INFO: ✓ Standardized time control categories\n",
      "INFO: ✓ Cleaned missing values: 447,391 → 447,391 rows\n",
      "INFO: Creating game-level player summary...\n",
      "INFO: ✓ Created game summary: 15,002 games\n",
      "INFO: ✓ Created player summary: 22 players\n",
      "INFO: ✓ Exported main dataset: /Users/benjaminrosales/Desktop/Chess-Worker/Chess-Study/Publication_Data/combined_processed_data.csv\n",
      "INFO: ✓ Exported game summary: /Users/benjaminrosales/Desktop/Chess-Worker/Chess-Study/Publication_Data/game_level_summary.csv\n",
      "INFO: ✓ Exported player summary: /Users/benjaminrosales/Desktop/Chess-Worker/Chess-Study/Publication_Data/player_level_summary.csv\n",
      "\n",
      "============================================================\n",
      "PUBLICATION DATA VERIFICATION REPORT\n",
      "============================================================\n",
      "\n",
      "📊 SAMPLE SIZES:\n",
      "Total moves: 447,391\n",
      "ADHD moves: 154,524\n",
      "Non-ADHD moves: 292,867\n",
      "\n",
      "🎯 ELO DISTRIBUTION:\n",
      "player_type   ADHD  Non-ADHD\n",
      "elo_bracket                 \n",
      "≤1000         4113      1720\n",
      "1001-1400    50618     51392\n",
      "1401-1800    62708    152285\n",
      "1801+        37085     87470\n",
      "\n",
      "⏱️ TIME CONTROL DISTRIBUTION:\n",
      "player_type             ADHD  Non-ADHD\n",
      "time_control_category                 \n",
      "Blitz                  88368    129956\n",
      "Bullet                 16722     68855\n",
      "Classical               2791      5199\n",
      "Rapid                  46643     88857\n",
      "\n",
      "👥 PLAYER COUNTS:\n",
      "Total unique players: 22\n",
      "ADHD players: 22\n",
      "Non-ADHD players: 0\n",
      "\n",
      "✅ DATA QUALITY CHECKS:\n",
      "Missing elo_bracket: 0\n",
      "Missing player_type: 0\n",
      "Missing time_spent: 0\n",
      "Missing position_complexity: 0\n",
      "\n",
      "📁 EXPORTED FILES:\n",
      "1. /Users/benjaminrosales/Desktop/Chess-Worker/Chess-Study/Publication_Data/combined_processed_data.csv\n",
      "2. /Users/benjaminrosales/Desktop/Chess-Worker/Chess-Study/Publication_Data/game_level_summary.csv\n",
      "3. /Users/benjaminrosales/Desktop/Chess-Worker/Chess-Study/Publication_Data/player_level_summary.csv\n",
      "\n",
      "🎉 DATA IS NOW PUBLICATION-READY!\n",
      "============================================================\n",
      "INFO: ✓ Created R loading script: /Users/benjaminrosales/Desktop/Chess-Worker/Chess-Study/Publication_Data/load_data.R\n",
      "\n",
      "📋 Next steps:\n",
      "1. Run your R regression scripts using combined_processed_data\n",
      "2. Use player_summary for between-subjects ANOVA\n",
      "3. All ELO brackets now match your paper exactly\n",
      "4. Professor Kleiman can run analyses immediately\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g5/_2wj4xfd1qzgc2kmmbxv4s6m0000gn/T/ipykernel_70801/3827741933.py:151: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  elo_dist = combined_processed_data.groupby(['elo_bracket', 'player_type']).size().unstack(fill_value=0)\n"
     ]
    }
   ],
   "source": [
    "# ======================================================================\n",
    "# PUBLICATION DATA FIXES\n",
    "# ======================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Apply this right after: logging.info(f\"Total number of moves after cleaning: {len(all_moves_df)}\")\n",
    "\n",
    "logging.info(\"=== APPLYING PUBLICATION-READY DATA FIXES ===\")\n",
    "\n",
    "# ----------------------- 1. FIX ELO BRACKETS TO MATCH PAPER -----------------------\n",
    "# Your paper uses ≤1000, 1001-1400, 1401-1800, 1801+ but current code uses different brackets\n",
    "\n",
    "# Create average ELO (more accurate than max)\n",
    "all_moves_df['avg_elo'] = (all_moves_df['white_elo'] + all_moves_df['black_elo']) / 2\n",
    "\n",
    "# FIX: Replace your existing elo_bracket creation with this:\n",
    "all_moves_df['elo_bracket'] = pd.cut(\n",
    "    all_moves_df['avg_elo'],\n",
    "    bins=[0, 1000, 1400, 1800, float('inf')],\n",
    "    labels=['≤1000', '1001-1400', '1401-1800', '1801+'],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "logging.info(\"✓ Fixed ELO brackets to match paper format\")\n",
    "\n",
    "# ----------------------- 2. CREATE PUBLICATION PLAYER TYPES -----------------------\n",
    "\n",
    "# Create clear player type variable for R ANOVA\n",
    "all_moves_df['player_type'] = all_moves_df['group'].map({\n",
    "    'ADHD': 'ADHD', \n",
    "    'General': 'Non-ADHD'  # This matches your R scripts!\n",
    "})\n",
    "\n",
    "# Create binary indicator for easier analysis\n",
    "all_moves_df['is_adhd_player'] = (all_moves_df['player_type'] == 'ADHD').astype(int)\n",
    "\n",
    "logging.info(\"✓ Created proper player_type variables\")\n",
    "\n",
    "# ----------------------- 3. FIX TIME CONTROL CATEGORIES -----------------------\n",
    "\n",
    "# Make sure time control categories match R scripts exactly\n",
    "time_control_mapping = {\n",
    "    'Bullet': 'Bullet',\n",
    "    'Blitz': 'Blitz', \n",
    "    'Rapid': 'Rapid',\n",
    "    'Classical': 'Classical'\n",
    "}\n",
    "\n",
    "all_moves_df['time_control_category'] = all_moves_df['time_control_category'].map(time_control_mapping)\n",
    "\n",
    "logging.info(\"✓ Standardized time control categories\")\n",
    "\n",
    "# ----------------------- 4. CLEAN MISSING VALUES FOR R -----------------------\n",
    "\n",
    "# Remove rows with critical missing values for regression analysis\n",
    "critical_vars = ['time_spent', 'move_number', 'position_complexity', 'elo_bracket', \n",
    "                'time_control_category', 'player_type']\n",
    "\n",
    "before_clean = len(all_moves_df)\n",
    "all_moves_df = all_moves_df.dropna(subset=critical_vars)\n",
    "after_clean = len(all_moves_df)\n",
    "\n",
    "logging.info(f\"✓ Cleaned missing values: {before_clean:,} → {after_clean:,} rows\")\n",
    "\n",
    "# ----------------------- 5. CREATE EXPORT-READY DATAFRAMES -----------------------\n",
    "\n",
    "# Create the main analysis dataset\n",
    "combined_processed_data = all_moves_df.copy()\n",
    "\n",
    "# Create game-level summary for between-subjects analysis\n",
    "logging.info(\"Creating game-level player summary...\")\n",
    "\n",
    "game_summary = combined_processed_data.groupby(['game_id', 'player_type']).agg({\n",
    "    'time_spent': ['mean', 'std', 'count'],\n",
    "    'eval_change': ['mean', 'std'],\n",
    "    'under_time_pressure': lambda x: (x == True).sum() / len(x),  # Proportion under pressure\n",
    "    'white_elo': 'first',\n",
    "    'black_elo': 'first',\n",
    "    'avg_elo': 'first',\n",
    "    'elo_bracket': 'first',\n",
    "    'time_control_category': 'first',\n",
    "    'adhd_player': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "game_summary.columns = [\n",
    "    'game_id', 'player_type', 'mean_time_spent', 'std_time_spent', 'n_moves',\n",
    "    'mean_eval_change', 'std_eval_change', 'prop_under_pressure',\n",
    "    'white_elo', 'black_elo', 'avg_elo', 'elo_bracket', 'time_control_category', 'adhd_player'\n",
    "]\n",
    "\n",
    "logging.info(f\"✓ Created game summary: {len(game_summary):,} games\")\n",
    "\n",
    "# ----------------------- 6. CREATE PLAYER-LEVEL SUMMARY -----------------------\n",
    "\n",
    "# This is what Professor Kleiman needs for ANOVA\n",
    "player_summary = game_summary.groupby(['adhd_player', 'player_type']).agg({\n",
    "    'mean_time_spent': ['mean', 'std', 'count'],\n",
    "    'mean_eval_change': ['mean', 'std'],\n",
    "    'prop_under_pressure': 'mean',\n",
    "    'avg_elo': 'mean',\n",
    "    'n_moves': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten columns\n",
    "player_summary.columns = [\n",
    "    'player_name', 'player_type', 'overall_mean_time', 'std_mean_time', 'n_games',\n",
    "    'overall_mean_eval_change', 'std_eval_change', 'avg_prop_under_pressure',\n",
    "    'average_elo', 'total_moves'\n",
    "]\n",
    "\n",
    "logging.info(f\"✓ Created player summary: {len(player_summary):,} players\")\n",
    "\n",
    "# ----------------------- 7. EXPORT FILES FOR R ANALYSIS -----------------------\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"/Users/benjaminrosales/Desktop/Chess-Worker/Chess-Study/Publication_Data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Export main dataset (what your R scripts expect)\n",
    "main_file = f\"{output_dir}/combined_processed_data.csv\"\n",
    "combined_processed_data.to_csv(main_file, index=False)\n",
    "logging.info(f\"✓ Exported main dataset: {main_file}\")\n",
    "\n",
    "# Export game-level summary\n",
    "game_file = f\"{output_dir}/game_level_summary.csv\"\n",
    "game_summary.to_csv(game_file, index=False)\n",
    "logging.info(f\"✓ Exported game summary: {game_file}\")\n",
    "\n",
    "# Export player-level summary (for ANOVA)\n",
    "player_file = f\"{output_dir}/player_level_summary.csv\"\n",
    "player_summary.to_csv(player_file, index=False)\n",
    "logging.info(f\"✓ Exported player summary: {player_file}\")\n",
    "\n",
    "# ----------------------- 8. CREATE DATA VERIFICATION REPORT -----------------------\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PUBLICATION DATA VERIFICATION REPORT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n📊 SAMPLE SIZES:\")\n",
    "print(f\"Total moves: {len(combined_processed_data):,}\")\n",
    "print(f\"ADHD moves: {len(combined_processed_data[combined_processed_data['player_type'] == 'ADHD']):,}\")\n",
    "print(f\"Non-ADHD moves: {len(combined_processed_data[combined_processed_data['player_type'] == 'Non-ADHD']):,}\")\n",
    "\n",
    "print(f\"\\n🎯 ELO DISTRIBUTION:\")\n",
    "elo_dist = combined_processed_data.groupby(['elo_bracket', 'player_type']).size().unstack(fill_value=0)\n",
    "print(elo_dist)\n",
    "\n",
    "print(f\"\\n⏱️ TIME CONTROL DISTRIBUTION:\")\n",
    "time_dist = combined_processed_data.groupby(['time_control_category', 'player_type']).size().unstack(fill_value=0)\n",
    "print(time_dist)\n",
    "\n",
    "print(f\"\\n👥 PLAYER COUNTS:\")\n",
    "print(f\"Total unique players: {len(player_summary)}\")\n",
    "print(f\"ADHD players: {len(player_summary[player_summary['player_type'] == 'ADHD'])}\")\n",
    "print(f\"Non-ADHD players: {len(player_summary[player_summary['player_type'] == 'Non-ADHD'])}\")\n",
    "\n",
    "print(f\"\\n✅ DATA QUALITY CHECKS:\")\n",
    "print(f\"Missing elo_bracket: {combined_processed_data['elo_bracket'].isna().sum()}\")\n",
    "print(f\"Missing player_type: {combined_processed_data['player_type'].isna().sum()}\")\n",
    "print(f\"Missing time_spent: {combined_processed_data['time_spent'].isna().sum()}\")\n",
    "print(f\"Missing position_complexity: {combined_processed_data['position_complexity'].isna().sum()}\")\n",
    "\n",
    "print(f\"\\n📁 EXPORTED FILES:\")\n",
    "print(f\"1. {main_file}\")\n",
    "print(f\"2. {game_file}\")\n",
    "print(f\"3. {player_file}\")\n",
    "\n",
    "print(\"\\n🎉 DATA IS NOW PUBLICATION-READY!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ----------------------- 9. CREATE R LOADING SNIPPET -----------------------\n",
    "\n",
    "r_code = f'''\n",
    "# ======================================================================\n",
    "# R CODE TO LOAD YOUR PUBLICATION DATA\n",
    "# Copy this into your R scripts\n",
    "# ======================================================================\n",
    "\n",
    "# Load the main dataset\n",
    "combined_processed_data <- read.csv(\"{main_file}\")\n",
    "\n",
    "# Load game-level summary\n",
    "game_summary <- read.csv(\"{game_file}\")\n",
    "\n",
    "# Load player-level summary (for ANOVA)\n",
    "player_summary <- read.csv(\"{player_file}\")\n",
    "\n",
    "# Verify data structure\n",
    "print(\"Data loaded successfully!\")\n",
    "print(paste(\"Total moves:\", nrow(combined_processed_data)))\n",
    "print(paste(\"ELO brackets:\", toString(unique(combined_processed_data$elo_bracket))))\n",
    "print(paste(\"Player types:\", toString(unique(combined_processed_data$player_type))))\n",
    "'''\n",
    "\n",
    "r_file = f\"{output_dir}/load_data.R\"\n",
    "with open(r_file, 'w') as f:\n",
    "    f.write(r_code)\n",
    "\n",
    "logging.info(f\"✓ Created R loading script: {r_file}\")\n",
    "\n",
    "print(f\"\\n📋 Next steps:\")\n",
    "print(f\"1. Run your R regression scripts using combined_processed_data\")\n",
    "print(f\"2. Use player_summary for between-subjects ANOVA\")\n",
    "print(f\"3. All ELO brackets now match your paper exactly\")\n",
    "print(f\"4. Professor Kleiman can run analyses immediately\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    330280.000000\n",
      "mean        -80.381882\n",
      "std         197.298415\n",
      "min       -3000.000000\n",
      "25%         -71.000000\n",
      "50%         -16.000000\n",
      "75%           0.000000\n",
      "max        1307.000000\n",
      "Name: eval_change, dtype: float64\n",
      "count     335386.0\n",
      "unique      6398.0\n",
      "top            0.0\n",
      "freq       15101.0\n",
      "Name: evaluation, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(adhd_moves_df['eval_change'].describe())\n",
    "print(adhd_moves_df['evaluation'].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import chess.pgn\n",
    "import io\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import chess.engine\n",
    "import sys\n",
    "import logging\n",
    "import math\n",
    "import random\n",
    "import tqdm\n",
    "from enum import Enum\n",
    "from elocator_test.complexity.model import ChessModel\n",
    "import torch\n",
    "from elocator_test.encoder import fen_encoder\n",
    "\n",
    "\n",
    "# Configure logging to print to stdout\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(levelname)s: %(message)s\", stream=sys.stdout\n",
    ")\n",
    "\n",
    "# Configure plotting style\n",
    "sns.set(style=\"whitegrid\")\n",
    "# Replace with the actual path to your general population PGN file\n",
    "GENERAL_PGN_FILE_PATH = \"/Users/benjaminrosales/Desktop/Chess Study Materials & Data/Comparison Games/lichess_db_standard_rated_2017-05.pgn\"\n",
    "\n",
    "# Path to your Stockfish executable\n",
    "STOCKFISH_PATH = \"/opt/homebrew/bin/stockfish\"\n",
    "\n",
    "# List of ADHD players' usernames (Lichess)\n",
    "ADHD_USERNAMES = [\n",
    "    \"teoeo\",\n",
    "    \"Tobermorey\",\n",
    "    \"apostatlet\",\n",
    "    \"LovePump1000\",\n",
    "    \"StuntmanAndy\",\n",
    "    \"Banfy_B\",\n",
    "    \"ChessyChesterton12\",\n",
    "    \"yastoon\",\n",
    "    \"Timy1976\",\n",
    "    \"SonnyDayz11\",\n",
    "    \"Xiroir\",\n",
    "    \"StellaAthena\",\n",
    "    \"MagikPigeon\"\n",
    "]\n",
    "\n",
    "#WrapperClass\n",
    "class ElocatorModel:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = ChessModel()\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "        self.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g5/_2wj4xfd1qzgc2kmmbxv4s6m0000gn/T/ipykernel_95730/3141903425.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(model_path))\n"
     ]
    }
   ],
   "source": [
    "class ElocatorAnalyzer:\n",
    "    def __init__(self, model_path):\n",
    "        self.model = ChessModel()\n",
    "        self.model.load_state_dict(torch.load(model_path))\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Correct percentile ranges from the repo\n",
    "        self.percentile_ranges = {\n",
    "            1: (0, 0.006848618667572737),\n",
    "            2: (0.006848618667572737, 0.007860606908798218),\n",
    "            3: (0.007860606908798218, 0.0093873867765069),\n",
    "            4: (0.0093873867765069, 0.010885232314467431),\n",
    "            5: (0.010885232314467431, 0.01191701553761959),\n",
    "            6: (0.01191701553761959, 0.012793240323662757),\n",
    "            7: (0.012793240323662757, 0.013946877606213093),\n",
    "            8: (0.013946877606213093, 0.015834777429699905),\n",
    "            9: (0.015834777429699905, 0.02067287489771843),\n",
    "            10: (0.02067287489771843, 1)\n",
    "        }\n",
    "    \n",
    "    def map_prediction_to_complexity(self, prediction):\n",
    "        \"\"\"Maps raw model output to complexity score (1-10)\"\"\"\n",
    "        for level, (low, high) in self.percentile_ranges.items():\n",
    "            if low <= prediction <= high:\n",
    "                return level\n",
    "        return None  # Handle predictions outside expected range\n",
    "    \n",
    "    def get_position_complexity(self, fen):\n",
    "        \"\"\"Get complexity score for a single position\"\"\"\n",
    "        try:\n",
    "            # Sanitize the FEN string before processing\n",
    "            clean_fen = sanitize_fen(fen)\n",
    "            if clean_fen is None:\n",
    "                return None\n",
    "                \n",
    "            encoded_position = fen_encoder(clean_fen)\n",
    "            position_tensor = torch.FloatTensor(encoded_position).unsqueeze(0)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                raw_prediction = self.model(position_tensor).item()\n",
    "                complexity_score = self.map_prediction_to_complexity(raw_prediction)\n",
    "                return complexity_score\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing FEN {fen}: {str(e)}\")\n",
    "            return None\n",
    "            \n",
    "    def analyze_game(self, pgn_game):\n",
    "        board = pgn_game.board()\n",
    "        node = pgn_game\n",
    "        positions = []\n",
    "        \n",
    "        # Get initial position\n",
    "        try:\n",
    "            complexity = self.get_position_complexity(board.fen())\n",
    "            positions.append({\n",
    "                'fen': board.fen(),\n",
    "                'complexity': complexity,\n",
    "                'move_number': 0\n",
    "            })\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error analyzing initial position: {str(e)}\")\n",
    "        \n",
    "        # Process each move\n",
    "        while node.variations:\n",
    "            try:\n",
    "                next_node = node.variations[0]\n",
    "                move = next_node.move\n",
    "                board.push(move)\n",
    "                \n",
    "                complexity = self.get_position_complexity(board.fen())\n",
    "                if complexity is not None:  # Only append positions we can analyze\n",
    "                    positions.append({\n",
    "                        'fen': board.fen(),\n",
    "                        'complexity': complexity,\n",
    "                        'move_number': len(board.move_stack)\n",
    "                    })\n",
    "                \n",
    "                node = next_node\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error analyzing position at move {len(board.move_stack)}: {str(e)}\")\n",
    "                break\n",
    "                \n",
    "        return positions\n",
    "\n",
    "# Create global instance\n",
    "elocator = ElocatorAnalyzer('elocator_test/complexity/models/model.pth')\n",
    "\n",
    "# Create global instance\n",
    "elocator = ElocatorAnalyzer('elocator_test/complexity/models/model.pth')\n",
    "# Create global instance\n",
    "elocator = ElocatorAnalyzer('elocator_test/complexity/models/model.pth')\n",
    "    \n",
    "def get_position_complexity(self, fen):\n",
    "        \"\"\"Get complexity score for a single position\"\"\"\n",
    "        encoded_position = fen_encoder(fen)\n",
    "        position_tensor = torch.FloatTensor(encoded_position).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            complexity = self.model(position_tensor)\n",
    "        return complexity.item()\n",
    "    \n",
    "def sanitize_fen(fen):\n",
    "    \"\"\"\n",
    "    Sanitize and validate a FEN string for standard chess.\n",
    "    Returns None if the FEN is invalid or from a variant game.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # If we see brackets or special characters, it's likely a variant game\n",
    "        if '[' in fen or ']' in fen or '~' in fen:\n",
    "            return None\n",
    "            \n",
    "        # Remove any non-standard characters\n",
    "        valid_chars = 'rnbqkpRNBQKP12345678/- '\n",
    "        cleaned_fen = ''.join(c for c in fen if c in valid_chars)\n",
    "        \n",
    "        # Get position part (everything before first space)\n",
    "        position_part = cleaned_fen.split()[0] if ' ' in cleaned_fen else cleaned_fen\n",
    "        \n",
    "        # Validate basic FEN structure\n",
    "        ranks = position_part.split('/')\n",
    "        if len(ranks) != 8:\n",
    "            return None\n",
    "            \n",
    "        # Validate each rank\n",
    "        for rank in ranks:\n",
    "            spaces = 0\n",
    "            for char in rank:\n",
    "                if char.isdigit():\n",
    "                    spaces += int(char)\n",
    "                else:\n",
    "                    spaces += 1\n",
    "            if spaces != 8:\n",
    "                return None\n",
    "                \n",
    "        # Return standardized FEN string\n",
    "        return f\"{position_part} w - - 0 1\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"FEN sanitization failed: {fen}\")\n",
    "        logging.error(f\"Error: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_int(value, default=None):\n",
    "    try:\n",
    "        return int(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return default\n",
    "\"\"\"\n",
    "Setting up Time Functions\n",
    "\"\"\"\n",
    "\n",
    "def parse_clock_time(comment):\n",
    "    match = re.search(r'\\[%clk (\\d+):(\\d+):(\\d+)\\]', comment)  # Adjust regex if needed\n",
    "    if match:\n",
    "        hours = int(match.group(1))\n",
    "        minutes = int(match.group(2))\n",
    "        seconds = int(match.group(3))\n",
    "        return hours * 3600 + minutes * 60 + seconds  # Total seconds\n",
    "    return None\n",
    "\n",
    "## Determine if a player is under time pressure based on van Harreveld et al. (2007) criteria ---\n",
    "\n",
    "def is_under_time_pressure(time_remaining, initial_time, time_spent):\n",
    "    \"\"\"\n",
    "    Determine time pressure, accounting for premoves and missing data\n",
    "    - Premoves (time_spent = 0) should never count as time pressure\n",
    "    - Missing time data should be handled safely\n",
    "    \"\"\"\n",
    "    # Handle None/missing values\n",
    "    if any(x is None for x in [time_remaining, initial_time]):\n",
    "        return False\n",
    "        \n",
    "    # Handle invalid values\n",
    "    try:\n",
    "        time_remaining = float(time_remaining)\n",
    "        initial_time = float(initial_time)\n",
    "        # time_spent can be None for missing data or 0 for premoves\n",
    "        time_spent = float(time_spent) if time_spent is not None else None\n",
    "    except (TypeError, ValueError):\n",
    "        return False\n",
    "        \n",
    "    # Invalid time states\n",
    "    if initial_time <= 0 or time_remaining < 0:\n",
    "        return False\n",
    "        \n",
    "    # If it's a premove (time_spent = 0) or missing time data,\n",
    "    # only check absolute and relative time remaining\n",
    "    absolute_pressure = time_remaining < 30  # Less than 30 seconds\n",
    "    relative_pressure = time_remaining < (0.1 * initial_time)  # Less than 10% of initial time\n",
    "        \n",
    "    return absolute_pressure or relative_pressure\n",
    "\n",
    "class TimeControlType(Enum):\n",
    "    CLASSICAL = \"Classical\"\n",
    "    RAPID = \"Rapid\"\n",
    "    BLITZ = \"Blitz\"\n",
    "    BULLET = \"Bullet\"\n",
    "    UNKNOWN = \"Unknown\"\n",
    "\n",
    "#Parsing and Categorizing Time Control\n",
    "def parse_time_control(time_control):\n",
    "    \"\"\"Parse time control string from Lichess format (already in seconds)\"\"\"\n",
    "    if not time_control or time_control == \"unknown\":\n",
    "        return None, None, TimeControlType.UNKNOWN\n",
    "        \n",
    "    try:\n",
    "        if \"+\" in time_control:\n",
    "            base, increment = time_control.split(\"+\")\n",
    "            initial_seconds = int(base)  # Already in seconds, don't multiply\n",
    "            increment_seconds = int(increment)\n",
    "        else:\n",
    "            initial_seconds = int(time_control)  # Already in seconds\n",
    "            increment_seconds = 0\n",
    "            \n",
    "        # Categorize based on seconds\n",
    "        if initial_seconds >= 1800:     # 30 minutes or more\n",
    "            category = TimeControlType.CLASSICAL\n",
    "        elif initial_seconds >= 600:     # 10 minutes or more\n",
    "            category = TimeControlType.RAPID\n",
    "        elif initial_seconds >= 180:     # 3 minutes or more\n",
    "            category = TimeControlType.BLITZ\n",
    "        else:                           # Less than 3 minutes\n",
    "            category = TimeControlType.BULLET\n",
    "            \n",
    "        return initial_seconds, increment_seconds, category\n",
    "        \n",
    "    except (ValueError, TypeError):\n",
    "        return None, None, TimeControlType.UNKNOWN\n",
    "\n",
    "def calculate_material(board):\n",
    "    # Returns material balance for both sides\n",
    "    material = {\"White\": 0, \"Black\": 0}\n",
    "    piece_values = {\n",
    "        chess.PAWN: 1,\n",
    "        chess.KNIGHT: 3,\n",
    "        chess.BISHOP: 3,\n",
    "        chess.ROOK: 5,\n",
    "        chess.QUEEN: 9,\n",
    "        chess.KING: 0,  # King is invaluable, but we set to 0 for simplicity\n",
    "    }\n",
    "    for piece_type in piece_values:\n",
    "        value = piece_values[piece_type]\n",
    "        material[\"White\"] += len(board.pieces(piece_type, chess.WHITE)) * value\n",
    "        material[\"Black\"] += len(board.pieces(piece_type, chess.BLACK)) * value\n",
    "    return material\n",
    "\n",
    "def categorize_position_complexity(evaluation):\n",
    "    \"\"\"\n",
    "    Categorize position complexity, handling both numeric and mate evaluations\n",
    "    \"\"\"\n",
    "    if evaluation is None:\n",
    "        return 'Unknown'\n",
    "    \n",
    "    # Handle mate scores\n",
    "    if isinstance(evaluation, str) and '#' in evaluation:\n",
    "        return 'Decisive Advantage'  # Mate is always decisive\n",
    "        \n",
    "    try:\n",
    "        eval_float = float(evaluation)\n",
    "        if abs(eval_float) < 1:\n",
    "            return 'Balanced'\n",
    "        elif abs(eval_float) < 3:\n",
    "            return 'Slight Advantage'\n",
    "        else:\n",
    "            return 'Decisive Advantage'\n",
    "    except (ValueError, TypeError):\n",
    "        return 'Unknown'\n",
    "\n",
    "def categorize_move(eval_before, eval_after):\n",
    "    \"\"\"\n",
    "    Categorize move quality, handling both numeric and mate evaluations\n",
    "    \"\"\"\n",
    "    if eval_before is None or eval_after is None:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    # Handle mate scores\n",
    "    if isinstance(eval_after, str) and '#' in eval_after:\n",
    "        if '-' in eval_after:\n",
    "            return \"Forced Checkmate (Losing)\"\n",
    "        return \"Forced Checkmate (Winning)\"\n",
    "    \n",
    "    try:\n",
    "        eval_before = float(eval_before)\n",
    "        eval_after = float(eval_after)\n",
    "    except (ValueError, TypeError):\n",
    "        return \"Unknown\"\n",
    "\n",
    "    # Now proceed with numeric evaluation\n",
    "    SATURATION_LIMIT = 1000  # Equivalent to a 10-pawn advantage\n",
    "    \n",
    "    # Calculate evaluation change\n",
    "    eval_change = eval_after - eval_before\n",
    "\n",
    "    if abs(eval_after) >= SATURATION_LIMIT:\n",
    "        return \"Winning Position\" if eval_after > 0 else \"Losing Position\"\n",
    "\n",
    "    # Categorize the move based on evaluation change\n",
    "    if eval_change <= -300:\n",
    "        return \"Blunder\"\n",
    "    elif eval_change <= -150:\n",
    "        return \"Mistake\"\n",
    "    elif eval_change <= -50:\n",
    "        return \"Inaccuracy\"\n",
    "    elif eval_change >= 300:\n",
    "        return \"Brilliant Move\"\n",
    "    elif eval_change >= 150:\n",
    "        return \"Great Move\"\n",
    "    elif eval_change >= 50:\n",
    "        return \"Good Move\"\n",
    "    else:\n",
    "        return \"Normal\"\n",
    "\n",
    "def debug_data_pipeline(df, label):\n",
    "    # Function definition here\n",
    "    logging.info(f\"Debugging {label}\")\n",
    "    # Process the DataFrame or print logs for debugging\n",
    "\n",
    "def raw_winning_chances(cp):\n",
    "    MULTIPLIER = -0.00368208\n",
    "    return 2 / (1 + math.exp(MULTIPLIER * cp)) - 1\n",
    "\n",
    "def cp_winning_chances(cp):\n",
    "    cp = max(-1000, min(cp, 1000))\n",
    "    return raw_winning_chances(cp)\n",
    "\n",
    "def mate_winning_chances(mate):\n",
    "    cp = (21 - min(10, abs(mate))) * 100\n",
    "    signed_cp = cp * (1 if mate > 0 else -1)\n",
    "    return raw_winning_chances(signed_cp)\n",
    "\n",
    "def eval_winning_chances(eval_str):\n",
    "    if eval_str is None:\n",
    "        return None\n",
    "    if '#' in str(eval_str):\n",
    "        # Mate in N moves\n",
    "        mate_str = str(eval_str).replace('#', '')\n",
    "        try:\n",
    "            mate = int(mate_str)\n",
    "            return mate_winning_chances(mate)\n",
    "        except ValueError:\n",
    "            return None\n",
    "    else:\n",
    "        try:\n",
    "            cp = float(eval_str) * 100  # Convert from pawns to centipawns\n",
    "            return cp_winning_chances(cp)\n",
    "        except ValueError:\n",
    "            return None\n",
    "\n",
    "\n",
    "def safe_int(value, default=None):\n",
    "    try:\n",
    "        return int(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return default\n",
    "\n",
    "\n",
    "def parse_clock_time(comment):\n",
    "    match = re.search(r'\\[%clk (\\d+):(\\d+):(\\d+)\\]', comment)  # Adjust regex if needed\n",
    "    if match:\n",
    "        hours = int(match.group(1))\n",
    "        minutes = int(match.group(2))\n",
    "        seconds = int(match.group(3))\n",
    "        return hours * 3600 + minutes * 60 + seconds  # Total seconds\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_evaluation(comment):\n",
    "    match = re.search(r'%eval\\s([+-]?[\\d.]+|#-?\\d+)', comment)\n",
    "    if match:\n",
    "        eval_str = match.group(1)\n",
    "        if '#' in eval_str:\n",
    "            # Mate in N moves\n",
    "            return eval_str\n",
    "        else:\n",
    "            return float(eval_str)  # Convert to float\n",
    "    return None\n",
    "\n",
    "\n",
    "def categorize_error(eval_change, player_color=\"white\"):\n",
    "    if eval_change is None:\n",
    "        return \"Unknown\"\n",
    "        \n",
    "    # Normalize eval_change to player's perspective\n",
    "    if player_color.lower() == \"black\":\n",
    "        eval_change = -eval_change\n",
    "        \n",
    "    # Now we're already in centipawns, no need to divide by 100\n",
    "    if eval_change <= -300:  \n",
    "        return \"Blunder\"\n",
    "    elif eval_change <= -150:\n",
    "        return \"Mistake\"\n",
    "    elif eval_change <= -50:\n",
    "        return \"Inaccuracy\"\n",
    "    else:\n",
    "        return \"Normal\"\n",
    "\n",
    "def calculate_material(board):\n",
    "    # Returns material balance for both sides\n",
    "    material = {\"White\": 0, \"Black\": 0}\n",
    "    piece_values = {\n",
    "        chess.PAWN: 1,\n",
    "        chess.KNIGHT: 3,\n",
    "        chess.BISHOP: 3,\n",
    "        chess.ROOK: 5,\n",
    "        chess.QUEEN: 9,\n",
    "        chess.KING: 0,  # King is invaluable, but we set to 0 for simplicity\n",
    "    }\n",
    "    for piece_type in piece_values:\n",
    "        value = piece_values[piece_type]\n",
    "        material[\"White\"] += len(board.pieces(piece_type, chess.WHITE)) * value\n",
    "        material[\"Black\"] += len(board.pieces(piece_type, chess.BLACK)) * value\n",
    "    return material\n",
    "\n",
    "def categorize_game_phase(board):\n",
    "    \"\"\"\n",
    "    Enhanced game phase calculation incorporating:\n",
    "    - Material balance and distribution\n",
    "    - Piece mobility\n",
    "    - Pawn structure\n",
    "    - Position characteristics\n",
    "    \"\"\"\n",
    "    # Material values calibrated from empirical analysis\n",
    "    PIECE_VALUES = {\n",
    "        chess.KNIGHT: 782,\n",
    "        chess.BISHOP: 830,\n",
    "        chess.ROOK: 1289,\n",
    "        chess.QUEEN: 2529\n",
    "    }\n",
    "    \n",
    "    # Phase boundaries from statistical analysis\n",
    "    ENDGAME_LIMIT = 3915   # ~Queen + Rook\n",
    "    MIDGAME_LIMIT = 15258  # Total non-pawn material at start\n",
    "    PHASE_MIDGAME = 128    # Full phase scale\n",
    "    \n",
    "    def calculate_piece_mobility(board, piece_type, square):\n",
    "        \"\"\"Calculate approximate mobility for a piece\"\"\"\n",
    "        mobility = 0\n",
    "        attacks = board.attacks(square)\n",
    "        mobility = len([sq for sq in attacks if not board.is_attacked_by(not board.turn, sq)])\n",
    "        return mobility\n",
    "    \n",
    "    def evaluate_pawn_structure(board):\n",
    "        \"\"\"Evaluate pawn structure impact on phase\"\"\"\n",
    "        white_pawns = board.pieces(chess.PAWN, chess.WHITE)\n",
    "        black_pawns = board.pieces(chess.PAWN, chess.BLACK)\n",
    "        \n",
    "        # Calculate pawn structure characteristics\n",
    "        center_pawns = len([p for p in white_pawns | black_pawns \n",
    "                          if chess.square_file(p) in [3,4]])\n",
    "        passed_pawns = 0\n",
    "        for p in white_pawns:\n",
    "            if not any(black_pawns & chess.BB_FILES[chess.square_file(p)]):\n",
    "                passed_pawns += 1\n",
    "        for p in black_pawns:\n",
    "            if not any(white_pawns & chess.BB_FILES[chess.square_file(p)]):\n",
    "                passed_pawns += 1\n",
    "                \n",
    "        return center_pawns * 0.1 + passed_pawns * 0.15\n",
    "    \n",
    "    # Calculate non-pawn material and mobility\n",
    "    def evaluate_position(color):\n",
    "        material = 0\n",
    "        mobility_factor = 0\n",
    "        \n",
    "        for piece_type, value in PIECE_VALUES.items():\n",
    "            pieces = board.pieces(piece_type, color)\n",
    "            count = len(pieces)\n",
    "            material += count * value\n",
    "            \n",
    "            # Add mobility consideration\n",
    "            for square in pieces:\n",
    "                mobility_factor += calculate_piece_mobility(board, piece_type, square) * 0.01\n",
    "                \n",
    "        return material, mobility_factor\n",
    "    \n",
    "    # Calculate for both sides\n",
    "    w_material, w_mobility = evaluate_position(chess.WHITE)\n",
    "    b_material, b_mobility = evaluate_position(chess.BLACK)\n",
    "    \n",
    "    # Total non-pawn material with mobility adjustment\n",
    "    total_material = w_material + b_material\n",
    "    mobility_adjustment = (w_mobility + b_mobility) * 100\n",
    "    \n",
    "    # Pawn structure impact\n",
    "    pawn_factor = evaluate_pawn_structure(board)\n",
    "    \n",
    "    # Adjust material based on mobility and pawn structure\n",
    "    adjusted_material = total_material * (1 + pawn_factor) + mobility_adjustment\n",
    "    \n",
    "    # Clamp between endgame and midgame limits\n",
    "    npm = max(ENDGAME_LIMIT, min(adjusted_material, MIDGAME_LIMIT))\n",
    "    \n",
    "    # Calculate phase score (0 = endgame, 128 = midgame)\n",
    "    phase = ((npm - ENDGAME_LIMIT) * PHASE_MIDGAME) // (MIDGAME_LIMIT - ENDGAME_LIMIT)\n",
    "    phase = max(0, min(phase, PHASE_MIDGAME))\n",
    "    \n",
    "    # Position-specific adjustments\n",
    "    if len(board.move_stack) <= 20:  # First 10 moves\n",
    "        phase = max(phase, 96)  # Ensure early moves are recognized as opening\n",
    "    \n",
    "    # Convert to categorical with clear documentation of thresholds\n",
    "    if phase >= 96:      # 75% of PHASE_MIDGAME - Clear opening characteristics\n",
    "        return \"Opening\"\n",
    "    elif phase >= 32:    # 25% of PHASE_MIDGAME - Significant material remains\n",
    "        return \"Middlegame\"\n",
    "    else:                # Limited material or simplified position\n",
    "        return \"Endgame\"\n",
    "\n",
    "def categorize_move(eval_before, eval_after):\n",
    "    if eval_before is None or eval_after is None:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    # Define saturation limits in centipawns\n",
    "    SATURATION_LIMIT = 1000  # Equivalent to a 10-pawn advantage\n",
    "    MATE_SCORE = 10000       # Arbitrary large value representing mate\n",
    "\n",
    "    # Calculate evaluation change\n",
    "    eval_change = eval_after - eval_before\n",
    "\n",
    "    # Handle mate scores (assuming the engine uses large numbers to indicate mate)\n",
    "    if abs(eval_after) >= MATE_SCORE:\n",
    "        if eval_after > 0:\n",
    "            return \"Forced Checkmate (Winning)\"\n",
    "        else:\n",
    "            return \"Forced Checkmate (Losing)\"\n",
    "\n",
    "    # Handle evaluation saturation\n",
    "    if abs(eval_after) >= SATURATION_LIMIT:\n",
    "        if eval_after > 0:\n",
    "            return \"Winning Position\"\n",
    "        else:\n",
    "            return \"Losing Position\"\n",
    "\n",
    "    # Categorize the move based on evaluation change\n",
    "    if eval_change <= -300:\n",
    "        return \"Blunder\"\n",
    "    elif eval_change <= -150:\n",
    "        return \"Mistake\"\n",
    "    elif eval_change <= -50:\n",
    "        return \"Inaccuracy\"\n",
    "    elif eval_change >= 300:\n",
    "        return \"Brilliant Move\"\n",
    "    elif eval_change >= 150:\n",
    "        return \"Great Move\"\n",
    "    elif eval_change >= 50:\n",
    "        return \"Good Move\"\n",
    "    else:\n",
    "        return \"Normal\"\n",
    "\n",
    "\n",
    "def debug_data_pipeline(df, label):\n",
    "    # Function definition here\n",
    "    logging.info(f\"Debugging {label}\")\n",
    "    # Process the DataFrame or print logs for debugging\n",
    "\n",
    "\n",
    "def raw_winning_chances(cp):\n",
    "    MULTIPLIER = -0.00368208\n",
    "    return 2 / (1 + math.exp(MULTIPLIER * cp)) - 1\n",
    "\n",
    "\n",
    "def cp_winning_chances(cp):\n",
    "    cp = max(-1000, min(cp, 1000))\n",
    "    return raw_winning_chances(cp)\n",
    "\n",
    "\n",
    "def mate_winning_chances(mate):\n",
    "    cp = (21 - min(10, abs(mate))) * 100\n",
    "    signed_cp = cp * (1 if mate > 0 else -1)\n",
    "    return raw_winning_chances(signed_cp)\n",
    "\n",
    "\n",
    "def eval_winning_chances(evaluation):\n",
    "    if evaluation is None:\n",
    "        return None\n",
    "    if isinstance(evaluation, str) and '#' in evaluation:\n",
    "        # Mate in N moves\n",
    "        mate_str = evaluation.replace('#', '')\n",
    "        try:\n",
    "            mate = int(mate_str)\n",
    "            return mate_winning_chances(mate)\n",
    "        except ValueError:\n",
    "            return None\n",
    "    else:\n",
    "        try:\n",
    "            cp = float(evaluation) * 100  # Convert from pawns to centipawns\n",
    "            return cp_winning_chances(cp)\n",
    "        except ValueError:\n",
    "            return None\n",
    "        \n",
    "\n",
    "def calculate_eval_change(prev_evaluation, evaluation, player):\n",
    "    if prev_evaluation is None or evaluation is None:\n",
    "        return None\n",
    "        \n",
    "    def process_eval(eval_str):\n",
    "        MAX_PAWNS = 15  # Cap at ±15 pawns\n",
    "        \n",
    "        if isinstance(eval_str, str) and '#' in eval_str:\n",
    "            mate_num = int(eval_str.replace('#', ''))\n",
    "            # Convert mate scores to pawns (not centipawns)\n",
    "            return MAX_PAWNS if mate_num > 0 else -MAX_PAWNS\n",
    "            \n",
    "        try:\n",
    "            # Keep everything in pawns and cap\n",
    "            val = float(eval_str)\n",
    "            return max(min(val, MAX_PAWNS), -MAX_PAWNS)\n",
    "        except ValueError:\n",
    "            return None\n",
    "    \n",
    "    try:\n",
    "        prev_val = process_eval(prev_evaluation)\n",
    "        curr_val = process_eval(evaluation)\n",
    "        \n",
    "        if prev_val is None or curr_val is None:\n",
    "            return None\n",
    "            \n",
    "        # Calculate change (still in pawns)\n",
    "        change = curr_val - prev_val\n",
    "        if player.lower() == \"black\":\n",
    "            change = -change\n",
    "            \n",
    "        return change\n",
    "        \n",
    "    except (ValueError, TypeError) as e:\n",
    "        logging.error(f\"Error calculating eval change: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_statistical_test(var, data, test_results, test_type=\"independent_t\"):\n",
    "    # Prepare data\n",
    "    group1 = data[data[\"Group\"] == \"ADHD\"][var].dropna()\n",
    "    group2 = data[data[\"Group\"] == \"General\"][var].dropna()\n",
    "\n",
    "    # Check if data is sufficient\n",
    "    if len(group1) < 10 or len(group2) < 10:\n",
    "        logging.warning(f\"Not enough data to perform statistical test on '{var}'.\")\n",
    "        return\n",
    "\n",
    "    # Test for normality\n",
    "    stat1, p1 = stats.shapiro(group1)\n",
    "    stat2, p2 = stats.shapiro(group2)\n",
    "    normal = p1 > 0.05 and p2 > 0.05\n",
    "\n",
    "    # Test for equal variances\n",
    "    stat_levene, p_levene = stats.levene(group1, group2)\n",
    "    equal_var = p_levene > 0.05\n",
    "\n",
    "    # Choose appropriate test\n",
    "    if normal and equal_var and test_type == \"independent_t\":\n",
    "        # Independent T-test\n",
    "        stat, p = stats.ttest_ind(group1, group2, equal_var=True)\n",
    "        test_name = \"Independent t-test\"\n",
    "    elif normal and not equal_var and test_type == \"independent_t\":\n",
    "        # Welch's T-test\n",
    "        stat, p = stats.ttest_ind(group1, group2, equal_var=False)\n",
    "        test_name = \"Welch's t-test\"\n",
    "    else:\n",
    "        # Mann-Whitney U Test\n",
    "        stat, p = stats.mannwhitneyu(group1, group2, alternative=\"two-sided\")\n",
    "        test_name = \"Mann-Whitney U test\"\n",
    "\n",
    "    test_results.append(\n",
    "        {\"Variable\": var, \"Test\": test_name, \"Statistic\": stat, \"p-value\": p}\n",
    "    )\n",
    "\n",
    "\n",
    "def perform_chi_squared_test(category_var, data, test_results):\n",
    "    contingency_table = pd.crosstab(data[\"Group\"], data[category_var])\n",
    "    if contingency_table.empty or contingency_table.shape[1] == 0:\n",
    "        logging.warning(f\"Contingency table is empty for variable '{category_var}'.\")\n",
    "        return\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
    "    test_results.append(\n",
    "        {\n",
    "            \"Variable\": category_var,\n",
    "            \"Test\": \"Chi-Squared test\",\n",
    "            \"Statistic\": chi2,\n",
    "            \"p-value\": p,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Game Processing Functions"
    ]
   },
   "outputs": [],
   "source": [
    "def fetch_lichess_games(username, max_games=4000):  # Increase max_games\n",
    "    url = f\"https://lichess.org/api/games/user/{username}\"\n",
    "    params = {\n",
    "        \"max\": max_games,\n",
    "        \"moves\": True,\n",
    "        \"evals\": True,  # Include evaluations in the PGN comments\n",
    "        \"clocks\": True,  # Include clock times in the PGN comments\n",
    "    }\n",
    "    headers = {\"Accept\": \"application/x-chess-pgn\"}\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    if response.status_code != 200:\n",
    "        logging.warning(\n",
    "            f\"Failed to fetch games for user '{username}'. Status code: {response.status_code}\"\n",
    "        )\n",
    "        return []\n",
    "    pgn_text = response.text\n",
    "    games = []\n",
    "    pgn_io = io.StringIO(pgn_text)\n",
    "    while True:\n",
    "        game = chess.pgn.read_game(pgn_io)\n",
    "        if game is None:\n",
    "            break\n",
    "\n",
    "        # Check if the game contains evaluations\n",
    "        has_evaluation = False\n",
    "        node = game\n",
    "        while node.variations:\n",
    "            next_node = node.variations[0]\n",
    "            comment = next_node.comment\n",
    "            if \"%eval\" in comment:\n",
    "                has_evaluation = True\n",
    "                break\n",
    "            node = next_node\n",
    "\n",
    "        if has_evaluation:\n",
    "            games.append(game)\n",
    "\n",
    "    logging.info(f\"Fetched {len(games)} games with evaluations for user '{username}'.\")\n",
    "    return games\n",
    "\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def count_games_in_pgn(pgn_file_path):\n",
    "    \"\"\"Count total games in PGN file with progress bar\"\"\"\n",
    "    count = 0\n",
    "    file_size = os.path.getsize(pgn_file_path)\n",
    "    \n",
    "    with open(pgn_file_path, \"r\", encoding=\"utf-8\") as pgn_file:\n",
    "        pbar = tqdm(total=file_size, desc=\"Counting games\", unit='B', unit_scale=True)\n",
    "        for line in pgn_file:\n",
    "            if line.startswith('[Event \"'):\n",
    "                count += 1\n",
    "            pbar.update(len(line.encode('utf-8')))\n",
    "        pbar.close()\n",
    "    return count\n",
    "\n",
    "def validate_game_evaluations(game):\n",
    "    \"\"\"Validate game has proper evaluation structure\"\"\"\n",
    "    try:\n",
    "        node = game\n",
    "        while node.variations:\n",
    "            next_node = node.variations[0]\n",
    "            if \"%eval\" in next_node.comment:\n",
    "                return True\n",
    "            node = next_node\n",
    "        return False\n",
    "    except (IndexError, AttributeError):\n",
    "        return False\n",
    "\n",
    "def process_pgn_file(pgn_file_path, max_games=10000, chunk_size=1000):\n",
    "    games = []\n",
    "    elo_distribution = {}\n",
    "    \n",
    "    try:\n",
    "        with open(pgn_file_path, \"r\", encoding=\"utf-8\") as pgn_file:\n",
    "            pbar = tqdm(total=max_games, desc=\"Collecting games\")\n",
    "            \n",
    "            while len(games) < max_games:\n",
    "                chunk_count = 0\n",
    "                current_chunk = []\n",
    "                \n",
    "                while chunk_count < chunk_size:\n",
    "                    game = chess.pgn.read_game(pgn_file)\n",
    "                    if game is None:\n",
    "                        break\n",
    "                        \n",
    "                    # Quick validation before adding to chunk\n",
    "                    if (game.headers and \n",
    "                        game.headers.get(\"Variant\", \"Standard\").lower() == \"standard\" and\n",
    "                        all(game.headers.get(key, \"\") != \"\" for key in [\"WhiteElo\", \"BlackElo\", \"TimeControl\"]) and\n",
    "                        validate_game_evaluations(game)):  # Added evaluation validation\n",
    "                        current_chunk.append(game)\n",
    "                        chunk_count += 1\n",
    "                \n",
    "                if not current_chunk:\n",
    "                    break\n",
    "                \n",
    "                sample_size = min(chunk_size // 2, max_games - len(games))\n",
    "                sampled_games = random.sample(current_chunk, min(sample_size, len(current_chunk)))\n",
    "                \n",
    "                for game in sampled_games:\n",
    "                    if len(games) >= max_games:\n",
    "                        break\n",
    "                    \n",
    "                    white_elo = safe_int(game.headers.get(\"WhiteElo\", 0))\n",
    "                    black_elo = safe_int(game.headers.get(\"BlackElo\", 0))\n",
    "                    time_control = game.headers.get(\"TimeControl\", \"unknown\")\n",
    "                    \n",
    "                    if all([white_elo, black_elo, time_control != \"unknown\"]):\n",
    "                        avg_elo = (white_elo + black_elo) // 2\n",
    "                        elo_bin = (avg_elo // 50) * 50\n",
    "                        elo_distribution[elo_bin] = elo_distribution.get(elo_bin, 0) + 1\n",
    "                        games.append(game)\n",
    "                        pbar.update(1)\n",
    "            \n",
    "            pbar.close()\n",
    "            \n",
    "            logging.info(\"\\nELO Distribution:\")\n",
    "            for elo_bin in sorted(elo_distribution.keys()):\n",
    "                count = elo_distribution[elo_bin]\n",
    "                logging.info(f\"ELO {elo_bin}-{elo_bin+50}: {count} games\")\n",
    "            \n",
    "        logging.info(f\"Successfully collected {len(games)} games\")\n",
    "                           \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to read PGN file '{pgn_file_path}': {e}\")\n",
    "    \n",
    "    return games\n",
    "\n",
    "# Usage\n",
    "logging.info(\"Fetching general population games...\")\n",
    "general_games = process_pgn_file(GENERAL_PGN_FILE_PATH, max_games=10000)\n",
    "\n",
    "# Usage with increased max_games\n",
    "logging.info(\"Fetching general population games...\")\n",
    "general_games = process_pgn_file(\n",
    "    GENERAL_PGN_FILE_PATH, \n",
    "    max_games=10000,\n",
    ")\n",
    "\n",
    "# Usage\n",
    "logging.info(\"Fetching general population games...\")\n",
    "general_games = process_pgn_file(\n",
    "    GENERAL_PGN_FILE_PATH, \n",
    "    max_games=10000,\n",
    ")\n",
    "\n",
    "def process_games(games, group_label, engine):\n",
    "    all_moves = []\n",
    "    total_games = len(games)\n",
    "    rated_games = 0\n",
    "    standard_games = 0\n",
    "    eval_games = 0\n",
    "    \n",
    "    logging.info(f\"\\nProcessing {total_games} games for {group_label} group\")\n",
    "    \n",
    "    for game in tqdm(games, desc=f\"Processing {group_label} games\"):\n",
    "        try:\n",
    "            # 1. Filter for standard chess and rated games\n",
    "            variant = game.headers.get(\"Variant\", \"Standard\")\n",
    "            event = game.headers.get(\"Event\", \"Unknown\")\n",
    "            \n",
    "            # Skip non-standard chess games\n",
    "            if variant.lower() != \"standard\":\n",
    "                continue\n",
    "            standard_games += 1\n",
    "            \n",
    "            # Check if game is rated (checking both headers and event description)\n",
    "            rated = (\"rated\" in event.lower() or \n",
    "                    game.headers.get(\"Rated\", \"False\").lower() == \"true\")\n",
    "            if not rated:\n",
    "                continue\n",
    "            rated_games += 1\n",
    "            \n",
    "            # 2. Initialize basic game data\n",
    "            board = game.board()\n",
    "            game_id = game.headers.get(\"Site\", \"Unknown\")\n",
    "            white = game.headers.get(\"White\", \"Unknown\")\n",
    "            black = game.headers.get(\"Black\", \"Unknown\")\n",
    "            result = game.headers.get(\"Result\", \"Unknown\")\n",
    "            white_elo = safe_int(game.headers.get(\"WhiteElo\", None))\n",
    "            black_elo = safe_int(game.headers.get(\"BlackElo\", None))\n",
    "            time_control = game.headers.get(\"TimeControl\", \"Unknown\")\n",
    "            \n",
    "            # 3. ADHD player identification\n",
    "            white_has_adhd = white in ADHD_USERNAMES\n",
    "            black_has_adhd = black in ADHD_USERNAMES\n",
    "            \n",
    "            # 4. Time control parsing\n",
    "            initial_time, increment, time_category = parse_time_control(time_control)\n",
    "            \n",
    "            # 5. Game traversal initialization\n",
    "            node = game\n",
    "            move_number = 0\n",
    "            prev_evaluation = None\n",
    "            current_material = calculate_material(board)\n",
    "            prev_time_remaining = None\n",
    "            prev_winning_chances = None\n",
    "            \n",
    "            # 6. Verify game has evaluations\n",
    "            if not any(\"%eval\" in node.variations[0].comment for node in game.mainline()):\n",
    "                continue\n",
    "            eval_games += 1\n",
    "\n",
    "            # 7. Process moves\n",
    "            while node.variations:\n",
    "                next_node = node.variations[0]\n",
    "                move = next_node.move\n",
    "                san = board.san(move)\n",
    "                move_number += 1\n",
    "                player = \"White\" if board.turn else \"Black\"\n",
    "                \n",
    "                # Get position evaluation data\n",
    "                try:\n",
    "                    position_complexity = elocator.get_position_complexity(board.fen())\n",
    "                except Exception as e:\n",
    "                    position_complexity = None\n",
    "                \n",
    "                # ADHD status for current move\n",
    "                is_adhd_move = (player == \"White\" and white_has_adhd) or \\\n",
    "                              (player == \"Black\" and black_has_adhd)\n",
    "                \n",
    "                # Extract move metadata\n",
    "                comment = next_node.comment\n",
    "                time_remaining = parse_clock_time(comment)\n",
    "                evaluation = parse_evaluation(comment)\n",
    "                \n",
    "                # Time calculations\n",
    "                time_spent = (prev_time_remaining - time_remaining) if all(x is not None for x in [prev_time_remaining, time_remaining]) else None\n",
    "                time_spent = time_spent if time_spent and time_spent > 0 else None\n",
    "                \n",
    "                under_pressure = is_under_time_pressure(\n",
    "                    time_remaining=time_remaining,\n",
    "                    initial_time=initial_time,\n",
    "                    time_spent=time_spent\n",
    "                )\n",
    "                \n",
    "                # Calculate winning chances\n",
    "                winning_chances = eval_winning_chances(evaluation)\n",
    "                winning_chances_change = winning_chances - prev_winning_chances if all(x is not None for x in [prev_winning_chances, winning_chances]) else None\n",
    "                \n",
    "                # Skip positions without evaluations\n",
    "                if evaluation is None:\n",
    "                    board.push(move)\n",
    "                    node = next_node\n",
    "                    prev_time_remaining = time_remaining\n",
    "                    current_material = calculate_material(board)\n",
    "                    prev_winning_chances = winning_chances\n",
    "                    continue\n",
    "                \n",
    "                # Execute move and calculate changes\n",
    "                board.push(move)\n",
    "                \n",
    "                # Evaluation change calculation\n",
    "                eval_change = calculate_eval_change(prev_evaluation, evaluation, player)\n",
    "                if eval_change is not None:\n",
    "                    eval_change = eval_change * 100\n",
    "\n",
    "                \n",
    "                new_material = calculate_material(board)\n",
    "                material_diff = new_material[player] - current_material[player]\n",
    "                is_sacrifice = material_diff < 0\n",
    "                game_phase = categorize_game_phase(board)\n",
    "                position_complexity_category = categorize_position_complexity(prev_evaluation)\n",
    "                error_category = categorize_error(eval_change, player)  # Note: passing player here is important\n",
    "                \n",
    "                # Compile move data\n",
    "                move_data = {\n",
    "                    'game_id': game_id,\n",
    "                    'event': event,\n",
    "                    'date': game.headers.get(\"UTCDate\", \"Unknown\"),\n",
    "                    'result': result,\n",
    "                    'white': white,\n",
    "                    'black': black,\n",
    "                    'white_elo': white_elo,\n",
    "                    'black_elo': black_elo,\n",
    "                    'adhd_player': white if white_has_adhd else (black if black_has_adhd else None),\n",
    "                    'move_number': move_number,\n",
    "                    'player': player,\n",
    "                    'san': san,\n",
    "                    'fen': board.fen(),\n",
    "                    'game_phase': game_phase,\n",
    "                    'is_adhd_move': is_adhd_move,\n",
    "                    'position_complexity': position_complexity,\n",
    "                    'position_complexity_category': position_complexity_category,\n",
    "                    'evaluation': evaluation,\n",
    "                    'eval_change': eval_change,\n",
    "                    'error_category': categorize_error(eval_change, player),\n",
    "                    'winning_chances': winning_chances,\n",
    "                    'winning_chances_change': winning_chances_change,\n",
    "                    'material_diff': material_diff,\n",
    "                    'is_sacrifice': is_sacrifice,\n",
    "                    'time_control': time_control,\n",
    "                    'time_control_category': time_category.value if time_category else None,\n",
    "                    'initial_time_seconds': initial_time,\n",
    "                    'increment_seconds': increment,\n",
    "                    'time_remaining': time_remaining,\n",
    "                    'time_spent': time_spent,\n",
    "                    'under_time_pressure': under_pressure,\n",
    "                    'group': group_label\n",
    "                }\n",
    "                \n",
    "                all_moves.append(move_data)\n",
    "                \n",
    "                # Update previous values\n",
    "                prev_evaluation = evaluation\n",
    "                prev_time_remaining = time_remaining\n",
    "                current_material = new_material\n",
    "                prev_winning_chances = winning_chances\n",
    "                node = next_node\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing game {game_id}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Processing summary\n",
    "    logging.info(f\"\\nProcessing Summary for {group_label}:\")\n",
    "    logging.info(f\"Total games: {total_games}\")\n",
    "    logging.info(f\"Standard chess games: {standard_games}\")\n",
    "    logging.info(f\"Rated games: {rated_games}\")\n",
    "    logging.info(f\"Games with evaluations: {eval_games}\")\n",
    "    logging.info(f\"Total moves processed: {len(all_moves)}\")\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    moves_df = pd.DataFrame(all_moves)\n",
    "    \n",
    "    return moves_df\n",
    "\n",
    "# If you want to specify a particular column order, you can reorder the DataFrame after creation.s\n",
    "column_order = [\n",
    "    'GameID', 'Event', 'Date', 'Result',\n",
    "    'White', 'Black', 'WhiteElo', 'BlackElo', 'ADHDPlayer',\n",
    "    'MoveNumber', 'Player', 'SAN', 'GamePhase', 'IsADHDMove',\n",
    "    'Evaluation', 'EvalChange', 'ErrorCategory', 'PositionComplexity', 'Position Complexity Category'\n",
    "    'MaterialDiff', 'IsSacrifice',\n",
    "    'TimeControl', 'TimeControlCategory', 'InitialTimeSeconds',\n",
    "    'IncrementSeconds', 'TimeRemaining', 'TimeSpent', 'UnderTimePressure',\n",
    "    'Group', 'MoveCondition'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.343120e+05\n",
      "mean    -4.651617e+05\n",
      "std      3.187952e+06\n",
      "min     -4.000000e+07\n",
      "25%     -8.700000e+03\n",
      "50%     -1.900000e+03\n",
      "75%      0.000000e+00\n",
      "max      1.993540e+07\n",
      "Name: eval_change, dtype: float64\n",
      "count     136504.0\n",
      "unique      4954.0\n",
      "top            0.0\n",
      "freq        5657.0\n",
      "Name: evaluation, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(adhd_moves_df['eval_change'].describe())\n",
    "print(adhd_moves_df['evaluation'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Fetching games for user 'teoeo'...\n",
      "INFO: Fetched 1252 games with evaluations for user 'teoeo'.\n",
      "INFO: Fetching games for user 'Tobermorey'...\n",
      "INFO: Fetched 190 games with evaluations for user 'Tobermorey'.\n",
      "INFO: Fetching games for user 'apostatlet'...\n",
      "INFO: Fetched 424 games with evaluations for user 'apostatlet'.\n",
      "INFO: Fetching games for user 'LovePump1000'...\n",
      "INFO: Fetched 583 games with evaluations for user 'LovePump1000'.\n",
      "INFO: Fetching games for user 'StuntmanAndy'...\n",
      "INFO: Fetched 825 games with evaluations for user 'StuntmanAndy'.\n",
      "INFO: Fetching games for user 'Banfy_B'...\n",
      "WARNING: Failed to fetch games for user 'Banfy_B'. Status code: 404\n",
      "INFO: Fetching games for user 'ChessyChesterton12'...\n",
      "INFO: Fetched 265 games with evaluations for user 'ChessyChesterton12'.\n",
      "INFO: Fetching games for user 'yastoon'...\n",
      "INFO: Fetched 24 games with evaluations for user 'yastoon'.\n",
      "INFO: Fetching games for user 'Timy1976'...\n",
      "WARNING: Failed to fetch games for user 'Timy1976'. Status code: 404\n",
      "INFO: Fetching games for user 'SonnyDayz11'...\n",
      "INFO: Fetched 16 games with evaluations for user 'SonnyDayz11'.\n",
      "INFO: Fetching games for user 'Xiroir'...\n",
      "INFO: Fetched 104 games with evaluations for user 'Xiroir'.\n",
      "INFO: Fetching games for user 'StellaAthena'...\n",
      "INFO: Fetched 162 games with evaluations for user 'StellaAthena'.\n",
      "INFO: Fetching games for user 'MagikPigeon'...\n",
      "INFO: Fetched 98 games with evaluations for user 'MagikPigeon'.\n",
      "INFO: Initialized Stockfish engine at '/opt/homebrew/bin/stockfish'.\n",
      "INFO: Processing ADHD players' games...\n",
      "INFO: \n",
      "Processing 3943 games for ADHD group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ADHD games: 100%|██████████| 3943/3943 [05:32<00:00, 11.87it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "Processing Summary for ADHD:\n",
      "INFO: Total games: 3943\n",
      "INFO: Standard chess games: 3684\n",
      "INFO: Rated games: 2192\n",
      "INFO: Games with evaluations: 2192\n",
      "INFO: Total moves processed: 136504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Debugging ADHD GAMES PROCESSING\n",
      "INFO: Fetching general population games...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting games: 100%|██████████| 10000/10000 [03:45<00:00, 44.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "ELO Distribution:\n",
      "INFO: ELO 800-850: 3 games\n",
      "INFO: ELO 850-900: 4 games\n",
      "INFO: ELO 900-950: 21 games\n",
      "INFO: ELO 950-1000: 34 games\n",
      "INFO: ELO 1000-1050: 68 games\n",
      "INFO: ELO 1050-1100: 98 games\n",
      "INFO: ELO 1100-1150: 143 games\n",
      "INFO: ELO 1150-1200: 194 games\n",
      "INFO: ELO 1200-1250: 249 games\n",
      "INFO: ELO 1250-1300: 300 games\n",
      "INFO: ELO 1300-1350: 363 games\n",
      "INFO: ELO 1350-1400: 491 games\n",
      "INFO: ELO 1400-1450: 559 games\n",
      "INFO: ELO 1450-1500: 655 games\n",
      "INFO: ELO 1500-1550: 668 games\n",
      "INFO: ELO 1550-1600: 690 games\n",
      "INFO: ELO 1600-1650: 684 games\n",
      "INFO: ELO 1650-1700: 732 games\n",
      "INFO: ELO 1700-1750: 679 games\n",
      "INFO: ELO 1750-1800: 624 games\n",
      "INFO: ELO 1800-1850: 563 games\n",
      "INFO: ELO 1850-1900: 507 games\n",
      "INFO: ELO 1900-1950: 435 games\n",
      "INFO: ELO 1950-2000: 355 games\n",
      "INFO: ELO 2000-2050: 266 games\n",
      "INFO: ELO 2050-2100: 193 games\n",
      "INFO: ELO 2100-2150: 146 games\n",
      "INFO: ELO 2150-2200: 101 games\n",
      "INFO: ELO 2200-2250: 74 games\n",
      "INFO: ELO 2250-2300: 34 games\n",
      "INFO: ELO 2300-2350: 19 games\n",
      "INFO: ELO 2350-2400: 12 games\n",
      "INFO: ELO 2400-2450: 16 games\n",
      "INFO: ELO 2450-2500: 8 games\n",
      "INFO: ELO 2500-2550: 6 games\n",
      "INFO: ELO 2550-2600: 4 games\n",
      "INFO: ELO 2600-2650: 1 games\n",
      "INFO: ELO 2650-2700: 1 games\n",
      "INFO: Successfully collected 10000 games\n",
      "INFO: Processing general population games...\n",
      "INFO: \n",
      "Processing 10000 games for General group\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing General games: 100%|██████████| 10000/10000 [24:51<00:00,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "Processing Summary for General:\n",
      "INFO: Total games: 10000\n",
      "INFO: Standard chess games: 10000\n",
      "INFO: Rated games: 10000\n",
      "INFO: Games with evaluations: 10000\n",
      "INFO: Total moves processed: 635243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Debugging GENERAL GAMES PROCESSING\n",
      "INFO: Combining datasets...\n",
      "INFO: Debugging COMBINED DATASET\n",
      "INFO: Cleaning data...\n",
      "INFO: Total number of moves after cleaning: 354666\n"
     ]
    }
   ],
   "source": [
    "# ----------------------- 1. Fetch and Process ADHD Players' Games -----------------------\n",
    "\n",
    "adhd_games = []\n",
    "for username in ADHD_USERNAMES:\n",
    "    logging.info(f\"Fetching games for user '{username}'...\")\n",
    "    user_games = fetch_lichess_games(username, max_games=4000)  # Adjust max_games as needed\n",
    "    adhd_games.extend(user_games)\n",
    "\n",
    "if not adhd_games:\n",
    "    logging.warning(\"No ADHD games fetched. Exiting analysis.\")\n",
    "else:\n",
    "    # Initialize the chess engine\n",
    "    try:\n",
    "        engine = chess.engine.SimpleEngine.popen_uci(STOCKFISH_PATH)\n",
    "        logging.info(f\"Initialized Stockfish engine at '{STOCKFISH_PATH}'.\")\n",
    "    except FileNotFoundError:\n",
    "        logging.critical(f\"Stockfish executable not found at '{STOCKFISH_PATH}'. Please update the path.\")\n",
    "        engine = None\n",
    "    except Exception as e:\n",
    "        logging.critical(f\"Failed to initialize Stockfish engine: {e}\")\n",
    "        engine = None\n",
    "\n",
    "    if engine is not None:\n",
    "        # ----------------------- 2. Process ADHD Players' Games -----------------------\n",
    "        \n",
    "        logging.info(\"Processing ADHD players' games...\")\n",
    "        adhd_moves_df = process_games(adhd_games, group_label='ADHD', engine=engine)\n",
    "        debug_data_pipeline(adhd_moves_df, \"ADHD GAMES PROCESSING\")\n",
    "        \n",
    "        # ----------------------- 3. Fetch and Process General Population Games -----------------------\n",
    "        \n",
    "        logging.info(\"Fetching general population games...\")\n",
    "        if not os.path.exists(GENERAL_PGN_FILE_PATH):\n",
    "            logging.error(f\"PGN file not found at path: {GENERAL_PGN_FILE_PATH}\")\n",
    "            general_games = []\n",
    "        else:\n",
    "            general_games = process_pgn_file(GENERAL_PGN_FILE_PATH, max_games = 10000)  # Adjust max_games as needed\n",
    "        \n",
    "        if not general_games:\n",
    "            logging.warning(\"No General population games to process.\")\n",
    "            general_moves_df = pd.DataFrame()\n",
    "        else:\n",
    "            logging.info(\"Processing general population games...\")\n",
    "            general_moves_df = process_games(general_games, group_label='General', engine=engine)\n",
    "            debug_data_pipeline(general_moves_df, \"GENERAL GAMES PROCESSING\")\n",
    "        \n",
    "        # ----------------------- 4. Combine Datasets -----------------------\n",
    "\n",
    "        logging.info(\"Combining datasets...\")\n",
    "        all_moves_df = pd.concat([adhd_moves_df, general_moves_df], ignore_index=True)\n",
    "        debug_data_pipeline(all_moves_df, \"COMBINED DATASET\")\n",
    "\n",
    "# ----------------------- 5. Data Cleaning -----------------------\n",
    "\n",
    "logging.info(\"Cleaning data...\")\n",
    "required_columns = ['time_spent', 'evaluation', 'eval_change', 'white_elo', 'black_elo']\n",
    "all_moves_df = all_moves_df.dropna(subset=required_columns)\n",
    "\n",
    "# Ensure 'is_sacrifice' (not 'IsSacrifice') is boolean\n",
    "all_moves_df['is_sacrifice'] = all_moves_df['is_sacrifice'].fillna(False).astype(bool)\n",
    "\n",
    "# Convert relevant columns to numeric types\n",
    "numeric_columns = ['time_spent', 'evaluation', 'eval_change', 'white_elo', 'black_elo']\n",
    "for col in numeric_columns:\n",
    "    all_moves_df[col] = pd.to_numeric(all_moves_df[col], errors='coerce')\n",
    "\n",
    "# Drop rows with NaNs resulted from non-numeric conversion\n",
    "all_moves_df = all_moves_df.dropna(subset=numeric_columns)\n",
    "\n",
    "# Create ELO brackets for analysis\n",
    "all_moves_df['elo_bracket'] = pd.cut(\n",
    "    all_moves_df.apply(lambda row: max(row['white_elo'], row['black_elo']), axis=1),\n",
    "    bins=[0, 1200, 1600, 2000, float('inf')],\n",
    "    labels=['0-1200', '1200-1600', '1600-2000', '2000+']\n",
    ")\n",
    "\n",
    "# After cleaning, output the number of moves remaining\n",
    "logging.info(f\"Total number of moves after cleaning: {len(all_moves_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Change Statistics:\n",
      "count    3.546660e+05\n",
      "mean    -1.564998e+05\n",
      "std      1.767131e+06\n",
      "min     -2.051770e+07\n",
      "25%     -7.800000e+03\n",
      "50%     -2.100000e+03\n",
      "75%     -4.000000e+02\n",
      "max      1.993540e+07\n",
      "Name: eval_change, dtype: float64\n",
      "\n",
      "Error Category Distribution:\n",
      "error_category\n",
      "Normal        51.0\n",
      "Blunder       45.4\n",
      "Mistake        2.0\n",
      "Inaccuracy     1.6\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Largest Evaluation Changes:\n",
      "        eval_change error_category  san\n",
      "110615   19935400.0        Blunder  Kg8\n",
      "13545    19922600.0        Blunder  Rf7\n",
      "41429    19901100.0         Normal  Ke2\n",
      "31089    19900900.0         Normal  Re8\n",
      "16294    19899900.0        Blunder   g5\n",
      "\n",
      "Smallest Evaluation Changes:\n",
      "        eval_change error_category   san\n",
      "526274  -20517700.0         Normal   Qf5\n",
      "731683  -20514000.0         Normal  Qf2+\n",
      "588414  -20245600.0         Normal  Qxc7\n",
      "509972  -20208100.0         Normal  Qc4+\n",
      "769244  -20205500.0         Normal  Qxd3\n"
     ]
    }
   ],
   "source": [
    "def analyze_error_distribution(df):\n",
    "    # Print actual value ranges\n",
    "    print(\"\\nEvaluation Change Statistics:\")\n",
    "    print(df['eval_change'].describe())\n",
    "    \n",
    "    # Count error categories\n",
    "    print(\"\\nError Category Distribution:\")\n",
    "    print(df['error_category'].value_counts(normalize=True).multiply(100).round(1))\n",
    "    \n",
    "    # Look at the largest eval changes\n",
    "    print(\"\\nLargest Evaluation Changes:\")\n",
    "    print(df.nlargest(5, 'eval_change')[['eval_change', 'error_category', 'san']])\n",
    "    \n",
    "    # Look at the smallest eval changes\n",
    "    print(\"\\nSmallest Evaluation Changes:\")\n",
    "    print(df.nsmallest(5, 'eval_change')[['eval_change', 'error_category', 'san']])\n",
    "\n",
    "# Add after your data cleaning\n",
    "analyze_error_distribution(all_moves_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
